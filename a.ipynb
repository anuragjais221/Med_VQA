{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/anurag'\n",
    "#****************************To be Change to reproduce ou result*********************************************\n",
    "\n",
    "# location of the data and where to store iamge feature image\n",
    "path_output_chd = path+'/Med_VQA'    \n",
    "\n",
    "input_vqa_train = 'train_dataset_pickle/train19_subset20_21_df.pkl'\n",
    "input_vqa_valid ='valid_dataset_pickle/val19_df.pkl'\n",
    "\n",
    "img_feat_train = 'train_dataset_pickle/train-image-feature-19-subset20.pickle'\n",
    "img_feat_valid ='valid_dataset_pickle/valid-image-feature-19-subset20.pickle'\n",
    "\n",
    "input_test = 'test_dataset_pickle/test19_df.pkl'\n",
    "img_feat_test = 'test_dataset_pickle/vgg19-test-image-feature.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "with open(path+'/Med_VQA/answer_classes.json', 'r') as j:\n",
    "        answer_classes = json.load(j)\n",
    "\n",
    "\n",
    "l = len(answer_classes) \n",
    "\n",
    "print(l)\n",
    "\n",
    "import easydict\n",
    "opt = easydict.EasyDict({\n",
    "        \"SEED\":97,\n",
    "        \"BATCH_SIZE\": 64,\n",
    "        \"VAL_BATCH_SIZE\": 64,\n",
    "        \"NUM_OUTPUT_UNITS\": l,\n",
    "        \"MAX_QUESTION_LEN\": 17,\n",
    "        \"IMAGE_CHANNEL\": 1984,\n",
    "        \"INIT_LEARNING_RATE\": 1e-4,\n",
    "        \"LAMNDA\":0.0001,\n",
    "        \"MFB_FACTOR_NUM\":5,\n",
    "        \"MFB_OUT_DIM\":1000,\n",
    "        \"BERT_UNIT_NUM\":768,\n",
    "        \"BERT_DROPOUT_RATIO\":0.3,\n",
    "        \"MFB_DROPOUT_RATIO\":0.1,\n",
    "        \"NUM_IMG_GLIMPSE\":2,\n",
    "        \"NUM_QUESTION_GLIMPSE\":2,\n",
    "        \"IMG_FEAT_SIZE\":1,\n",
    "        \"IMG_INPUT_SIZE\":224,\n",
    "        \"NUM_EPOCHS\":150,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = np.load(path+'/Med_VQA/'+input_vqa_train, allow_pickle=True)\n",
    "# test_data_df = np.load(path+'/VQA_Med'+input_test,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14216, 5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_df['labels'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>PATH</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synpic41148</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>/home/anurag/Med_VQA/data/raw/ImageCLEF/train_...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synpic43984</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>no</td>\n",
       "      <td>/home/anurag/Med_VQA/data/raw/ImageCLEF/train_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synpic38930</td>\n",
       "      <td>what type of imaging modality is used to acqui...</td>\n",
       "      <td>us - ultrasound</td>\n",
       "      <td>/home/anurag/Med_VQA/data/raw/ImageCLEF/train_...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synpic52143</td>\n",
       "      <td>is this a noncontrast mri?</td>\n",
       "      <td>no</td>\n",
       "      <td>/home/anurag/Med_VQA/data/raw/ImageCLEF/train_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synpic20934</td>\n",
       "      <td>what type of image modality is this?</td>\n",
       "      <td>xr - plain film</td>\n",
       "      <td>/home/anurag/Med_VQA/data/raw/ImageCLEF/train_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                                  Q   \n",
       "0  synpic41148                        what kind of image is this?  \\\n",
       "1  synpic43984                       is this a t1 weighted image?   \n",
       "2  synpic38930  what type of imaging modality is used to acqui...   \n",
       "3  synpic52143                         is this a noncontrast mri?   \n",
       "4  synpic20934               what type of image modality is this?   \n",
       "\n",
       "                      A                                               PATH   \n",
       "0  cta - ct angiography  /home/anurag/Med_VQA/data/raw/ImageCLEF/train_...  \\\n",
       "1                    no  /home/anurag/Med_VQA/data/raw/ImageCLEF/train_...   \n",
       "2       us - ultrasound  /home/anurag/Med_VQA/data/raw/ImageCLEF/train_...   \n",
       "3                    no  /home/anurag/Med_VQA/data/raw/ImageCLEF/train_...   \n",
       "4       xr - plain film  /home/anurag/Med_VQA/data/raw/ImageCLEF/train_...   \n",
       "\n",
       "   labels  \n",
       "0      32  \n",
       "1       2  \n",
       "2      15  \n",
       "3       2  \n",
       "4       5  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_data_df = np.load(path+'/Med_VQA/'+input_vqa_valid,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_df = np.load(path+'/Med_VQA/'+input_test,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import easydict\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import time\n",
    "import re\n",
    "from torchinfo import summary\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import bleu_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import copy\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import VisualBertModel, VisualBertConfig\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anurag/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device',device)\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = opt.SEED\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "torch.manual_seed(seed_value) # return <torch._C.Generator object at 0x7f71cdf7a3d0>\n",
    "torch.cuda.manual_seed(seed_value) \n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VqaDataset(data.Dataset):\n",
    "    '''\n",
    "        Main class use to retrieve our dataset from pickle file.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_dir, input_vqa, img_feat_vqa, transform=None, phase = 'train'):\n",
    "        # print('vqa_path',input_dir+'/'+input_vqa)\n",
    "        # print('feat_path',input_dir+'/'+img_feat_vqa)\n",
    "        self.input_dir = input_dir\n",
    "        self.vqa = np.load(input_dir+'/'+input_vqa, allow_pickle=True )\n",
    "        self.img_feat_vqa = np.load(input_dir+'/'+img_feat_vqa, allow_pickle=True )\n",
    "        self.vocab_size = None\n",
    "        self.phase = phase\n",
    "        # print('vqa',self.vqa)\n",
    "        # print('img_feat_vqa',type(self.img_feat_vqa))\n",
    "   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        vqa = self.vqa\n",
    "        img_feat_vqa = self.img_feat_vqa\n",
    "        image_id = vqa['ID'].values[idx]\n",
    "        image_feat = torch.Tensor(img_feat_vqa[image_id])\n",
    "        sample = { 'image_feature':image_feat ,  } \n",
    "        if (self.phase == 'train' or self.phase == 'valid'):\n",
    "            qst2dic = vqa['Q'].values[idx]  \n",
    "            answer = vqa['A'].values[idx]\n",
    "            label = vqa['labels'].values[idx]\n",
    "            sample['question'] = qst2dic\n",
    "            sample['answer'] = answer\n",
    "            sample['label'] = label\n",
    "        else:\n",
    "            sample['image_id'] = image_id\n",
    "            sample['question'] = vqa['Question'].values[idx]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.vqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class VqaDataset(data.Dataset):\n",
    "#     '''\n",
    "#         Main class use to retrieve our dataset from pickle file.\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, input_dir, input_vqa, img_feat_vqa, transform=None, phase = 'train'):\n",
    "#         # print('vqa_path',input_dir+'/'+input_vqa)\n",
    "#         # print('feat_path',input_dir+'/'+img_feat_vqa)\n",
    "#         self.input_dir = input_dir\n",
    "#         self.vqa = np.load(input_dir+'/'+input_vqa, allow_pickle=True )\n",
    "#         self.img_feat_vqa = np.load(input_dir+'/'+img_feat_vqa, allow_pickle=True )\n",
    "#         self.vocab_size = None\n",
    "#         self.phase = phase\n",
    "#         # print('vqa',self.vqa)\n",
    "#         # print('img_feat_vqa',type(self.img_feat_vqa))\n",
    "   \n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "#         vqa = self.vqa\n",
    "#         img_feat_vqa = self.img_feat_vqa\n",
    "#         image_id = vqa['image_id'].values[idx]\n",
    "#         image_feat = torch.Tensor(img_feat_vqa[image_id])\n",
    "#         sample = { 'image_feature':image_feat ,  } \n",
    "#         if (self.phase == 'train'):\n",
    "#             ans2idc_a = vqa['labels_a'].values[idx]\n",
    "#             ans2dic_b = vqa['labels_b'].values[idx]\n",
    "#             answer_a = vqa['answer_a'].values[idx]\n",
    "#             answer_b = vqa['answer_b'].values[idx]\n",
    "#             question_a = vqa['question_a'].values[idx]\n",
    "#             question_b = vqa['question_b'].values[idx]\n",
    "#             sample['label_a'] = ans2idc_a\n",
    "#             sample['label_b'] = ans2dic_b\n",
    "#             sample['answer_a'] = answer_a\n",
    "#             sample['answer_b'] = answer_b\n",
    "#             sample['question_a'] = question_a\n",
    "#             sample['question_b'] = question_b\n",
    "#             sample['lamda'] = vqa['lamda'].values[idx]\n",
    "\n",
    "#         elif (self.phase == 'valid'):\n",
    "#             qst2dic = vqa['Question'].values[idx]  \n",
    "#             answer = vqa['Answer'].values[idx]\n",
    "#             label = vqa['labels'].values[idx]\n",
    "#             sample['question'] = qst2dic\n",
    "#             sample['answer'] = answer\n",
    "#             sample['label'] = label\n",
    "        \n",
    "#         else:\n",
    "#             sample['image_id'] = image_id\n",
    "#             sample['question'] = vqa['Question'].values[idx]\n",
    "            \n",
    "            \n",
    "#         return sample\n",
    "\n",
    "#     def __len__(self):\n",
    "\n",
    "#         return len(self.vqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loader(input_dir, input_vqa_train, input_vqa_valid, img_feat_train, img_feat_valid, batch_size, num_workers,size=228):\n",
    "    '''\n",
    "        Load our dataset with dataloader for the train and valid data\n",
    "    '''\n",
    "\n",
    "    vqa_dataset = {\n",
    "        'train': VqaDataset(\n",
    "            input_dir=input_dir,\n",
    "            input_vqa=input_vqa_train,\n",
    "            img_feat_vqa=img_feat_train,\n",
    "            phase = 'train'),\n",
    "        'valid': VqaDataset(\n",
    "            input_dir=input_dir,\n",
    "            input_vqa=input_vqa_valid,\n",
    "            img_feat_vqa=img_feat_valid,\n",
    "            phase = 'valid')}\n",
    "    \n",
    "\n",
    "    data_loader = {\n",
    "        phase: torch.utils.data.DataLoader(\n",
    "            dataset=vqa_dataset[phase],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            )\n",
    "        for phase in ['train','valid']}\n",
    "\n",
    "    return data_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTokenizer():\n",
    "\n",
    "    def __init__(self,opt):\n",
    "        # Load the BERT tokenizer\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "        self.opt = opt\n",
    "    #pre-process the text data\n",
    "    def text_preprocessing(self, text):\n",
    "\n",
    "        # Remove trailing whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "    # Create a function to tokenize a set of texts\n",
    "    def preprocessing_for_bert(self, data):\n",
    "        \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "        @param    data (np.array): Array of texts to be processed.\n",
    "        @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "        @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                    tokens should be attended to by the model.\n",
    "        \"\"\"\n",
    "        # Create empty lists to store outputs\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        MAX_LEN = self.opt.MAX_QUESTION_LEN\n",
    "        # For every sentence...\n",
    "        for sent in data:\n",
    "            \n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=self.text_preprocessing(sent),  # Preprocess sentence\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "                max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length\n",
    "                #return_tensors='pt',           # Return PyTorch tensor\n",
    "                truncation=True,\n",
    "                return_attention_mask=True      # Return attention mask\n",
    "                )\n",
    "            \n",
    "            # Add the outputs to the lists\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "        inputs = { 'input_ids' : input_ids, 'attention_mask': attention_masks }\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the question feature with co-attention\n",
    "class QuestionFeatureExtractionAtt(nn.Module):\n",
    "    '''\n",
    "        Extract the question with co-attention, get from https://github.com/asdf0982/vqa-mfb.pytorch \n",
    "    '''\n",
    "\n",
    "    def __init__(self,opt):\n",
    "\n",
    "        super(QuestionFeatureExtractionAtt, self).__init__()\n",
    "\n",
    "        self.opt = opt\n",
    "        self.NUM_QUESTION_GLIMPSE = self.opt.NUM_QUESTION_GLIMPSE #2\n",
    "                                          # 5                    #1000\n",
    "        self.JOINT_EMB_SIZE = self.opt.MFB_FACTOR_NUM * self.opt.MFB_OUT_DIM\n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "                                                    #768                       #2\n",
    "        self.Linear1_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM* self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n",
    "        self.Linear2_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM*self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n",
    "        \n",
    "        self.Dropout_M = nn.Dropout(p=self.opt.MFB_DROPOUT_RATIO)\n",
    "        self.dropout = nn.Dropout(self.opt.BERT_DROPOUT_RATIO) \n",
    "        self.Conv1_Qatt = nn.Conv2d(self.opt.BERT_UNIT_NUM, self.opt.IMAGE_CHANNEL, 1) \n",
    "        self.Conv2_Qatt = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.opt.NUM_QUESTION_GLIMPSE, 1)\n",
    "\n",
    "    def forward(self,qst_encoding):\n",
    "\n",
    "        '''\n",
    "        Question Attention\n",
    "        '''   \n",
    "        self.batch_size = qst_encoding.shape[0]\n",
    "        qst_encoding = self.dropout(qst_encoding)\n",
    "        qst_encoding_resh =  torch.unsqueeze(qst_encoding, 3)       # N=4 x 768 x T=14 x 1     \n",
    "        qatt_conv1 = self.Conv1_Qatt(qst_encoding_resh)                   # N x 512 x T x 1\n",
    "        qatt_relu = F.relu(qatt_conv1)\n",
    "        qatt_conv2 = self.Conv2_Qatt(qatt_relu)                          # N x 2 x T x 1\n",
    "        qatt_conv2 = qatt_conv2.contiguous().view(self.batch_size*2,-1)\n",
    "        qatt_softmax = self.Softmax(qatt_conv2)\n",
    "        qatt_softmax = qatt_softmax.view(self.batch_size, 2, -1, 1)\n",
    "        qatt_feature_list = []\n",
    "        for i in range(self.NUM_QUESTION_GLIMPSE):\n",
    "            t_qatt_mask = qatt_softmax.narrow(1, i, 1)              # N x 1 x T x 1\n",
    "            t_qatt_mask = t_qatt_mask * qst_encoding_resh           # N x 768 x T x 1\n",
    "            t_qatt_mask = torch.sum(t_qatt_mask, 2, keepdim=True)   # N x 768 x 1 x 1\n",
    "            qatt_feature_list.append(t_qatt_mask)\n",
    "        qatt_feature_concat = torch.cat(qatt_feature_list, 1)       # N x 1536 x 1 x 1\n",
    "\n",
    "        return qatt_feature_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the image feature with MFB and co-attention \n",
    "class ImageFeatureExtractionAtt(nn.Module):\n",
    "\n",
    "    '''\n",
    "        Extract the image with co-attention, get from https://github.com/asdf0982/vqa-mfb.pytorch \n",
    "    '''\n",
    "\n",
    "    def __init__(self,opt):\n",
    "        super(ImageFeatureExtractionAtt, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.MFB_FACTOR_NUM = self.opt.MFB_FACTOR_NUM\n",
    "        self.MFB_OUT_DIM = self.opt.MFB_OUT_DIM\n",
    "        self.NUM_IMG_GLIMPSE =self.opt.NUM_IMG_GLIMPSE\n",
    "        self.IMG_FEAT_SIZE = self.opt.IMG_FEAT_SIZE\n",
    "        \n",
    "        self.JOINT_EMB_SIZE = self.opt.MFB_FACTOR_NUM * self.opt.MFB_OUT_DIM\n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.Linear1_q_proj = nn.Linear(self.opt.BERT_UNIT_NUM* self.opt.NUM_QUESTION_GLIMPSE, self.JOINT_EMB_SIZE)\n",
    "        self.Linear_i_proj = nn.Linear(self.opt.IMAGE_CHANNEL*self.opt.NUM_IMG_GLIMPSE, self.JOINT_EMB_SIZE)\n",
    "        self.Conv_i_proj = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.JOINT_EMB_SIZE, 1)\n",
    "        \n",
    "\n",
    "        self.Dropout_M = nn.Dropout(p=self.opt.MFB_DROPOUT_RATIO)\n",
    "\n",
    "        self.Conv1_Iatt = nn.Conv2d(self.opt.MFB_OUT_DIM, self.opt.IMAGE_CHANNEL, 1) # (1000, 512, 1)\n",
    "        self.Conv2_Iatt = nn.Conv2d(self.opt.IMAGE_CHANNEL, self.NUM_IMG_GLIMPSE, 1)\n",
    "    \n",
    "    def forward(self, img_feature, qstatt_feature):\n",
    "\n",
    "        '''\n",
    "        Image Attention with MFB\n",
    "        '''\n",
    "        self.batch_size = img_feature.shape[0]\n",
    "        q_feat_resh = torch.squeeze(qstatt_feature)                              # N x 1536\n",
    "        i_feat_resh = img_feature.unsqueeze(3)                                   # N x 512 x 196 x 1\n",
    "        iatt_q_proj = self.Linear1_q_proj(q_feat_resh)                                  # N x 5000\n",
    "        iatt_q_resh = iatt_q_proj.view(self.batch_size, self.JOINT_EMB_SIZE, 1, 1)      # N x 5000 x 1 x 1\n",
    "        iatt_i_conv = self.Conv_i_proj(i_feat_resh)                                     # N x 5000 x 196 x 1\n",
    "        iatt_iq_eltwise = iatt_q_resh * iatt_i_conv\n",
    "        iatt_iq_droped = self.Dropout_M(iatt_iq_eltwise)                                # N x 5000 x 196 x 1\n",
    "        iatt_iq_permute1 = iatt_iq_droped.permute(0,2,1,3).contiguous()                 # N x 196 x 5000 x 1\n",
    "        iatt_iq_resh = iatt_iq_permute1.view(self.batch_size, self.IMG_FEAT_SIZE, self.MFB_OUT_DIM, self.MFB_FACTOR_NUM)\n",
    "        iatt_iq_sumpool = torch.sum(iatt_iq_resh, 3, keepdim=True)                      # N x 196 x 1000 x 1 \n",
    "        iatt_iq_permute2 = iatt_iq_sumpool.permute(0,2,1,3)                             # N x 1000 x 196 x 1\n",
    "        iatt_iq_sqrt = torch.sqrt(F.relu(iatt_iq_permute2)) - torch.sqrt(F.relu(-iatt_iq_permute2))\n",
    "        iatt_iq_sqrt = iatt_iq_sqrt.reshape(self.batch_size, -1)                           # N x 196000\n",
    "        iatt_iq_l2 = F.normalize(iatt_iq_sqrt)\n",
    "        iatt_iq_l2 = iatt_iq_l2.view(self.batch_size, self.MFB_OUT_DIM, self.IMG_FEAT_SIZE, 1)  # N x 1000 x 196 x 1\n",
    "\n",
    "        iatt_conv1 = self.Conv1_Iatt(iatt_iq_l2)                    # N x 512 x 196 x 1\n",
    "        iatt_relu = F.relu(iatt_conv1)\n",
    "        iatt_conv2 = self.Conv2_Iatt(iatt_relu)                     # N x 2 x 196 x 1\n",
    "        iatt_conv2 = iatt_conv2.view(self.batch_size*self.NUM_IMG_GLIMPSE, -1)\n",
    "        iatt_softmax = self.Softmax(iatt_conv2)\n",
    "        iatt_softmax = iatt_softmax.view(self.batch_size, self.NUM_IMG_GLIMPSE, -1, 1)\n",
    "        iatt_feature_list = []\n",
    "        for i in range(self.NUM_IMG_GLIMPSE):\n",
    "            t_iatt_mask = iatt_softmax.narrow(1, i, 1)              # N x 1 x 196 x 1\n",
    "            t_iatt_mask = t_iatt_mask * i_feat_resh                 # N x 512 x 196 x 1\n",
    "            t_iatt_mask = torch.sum(t_iatt_mask, 2, keepdim=True)   # N x 512 x 1 x 1\n",
    "            iatt_feature_list.append(t_iatt_mask)\n",
    "        iatt_feature_concat = torch.cat(iatt_feature_list, 1)       # N x 1024 x 1 x 1\n",
    "        iatt_feature_concat = torch.squeeze(iatt_feature_concat)    # N x 1024\n",
    "        return iatt_feature_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualBertClassification(nn.Module):\n",
    "    def __init__(self,opt,num_classes=178,emb_size=512):\n",
    "        super(VisualBertClassification,self).__init__()\n",
    "        VBconfig = VisualBertConfig(visual_embedding_dim=1984)\n",
    "        self.opt = opt\n",
    "        self.tokenizer = BERTokenizer(self.opt)\n",
    "        self.model = VisualBertModel(VBconfig)\n",
    "        self.linear_text = nn.Linear(768,emb_size)\n",
    "        self.linear_img = nn.Linear(768, emb_size)\n",
    "        \n",
    "        self.classifier = nn.Linear(emb_size*2,num_classes)\n",
    "\n",
    "    def forward(self,visual_embeds,questions):\n",
    "        \n",
    "        # print('visual_embeds',visual_embeds.shape)\n",
    "        visual_embeds = visual_embeds.transpose(1,2)\n",
    "        inputs = self.tokenizer.preprocessing_for_bert(questions)\n",
    "        visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long).to(device)\n",
    "        # print('visual_token_type_ids',visual_token_type_ids.shape)\n",
    "        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float).to(device)\n",
    "        # print('visual_attention_mask',visual_attention_mask.shape)\n",
    "        inputs.update(\n",
    "            {\n",
    "                \"visual_embeds\": visual_embeds,\n",
    "                \"visual_token_type_ids\": visual_token_type_ids,\n",
    "                \"visual_attention_mask\": visual_attention_mask,\n",
    "                \"output_attentions\":True\n",
    "            }\n",
    "        ) \n",
    "        inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "        # inputs['token_type_ids'] = inputs['token_type_ids'].to(device)\n",
    "        inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "        inputs['visual_token_type_ids'] = inputs['visual_token_type_ids'].to(device)\n",
    "        inputs['visual_attention_mask'] = inputs['visual_attention_mask'].to(device)\n",
    "\n",
    "        outputs = self.model(**inputs)\n",
    "        # print('outputs',outputs[1].shape)\n",
    "        # print('pooler_output',outputs['pooler_output'].shape)\n",
    "        # print('out',outputs[1].shape)\n",
    "        # print('out2',outputs[0][:, 0])\n",
    "        text_emb = self.linear_text(outputs[0][:,0])\n",
    "        # print('text_emb',text_emb.shape)\n",
    "        img_emb = self.linear_img(outputs[1])\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        combined_emb = torch.cat((img_emb,text_emb),dim=1)\n",
    "        # print('combined',combined_emb)\n",
    "        logits = self.classifier(combined_emb)\n",
    "        # print('logits',logits)\n",
    "        return logits,img_emb,text_emb\n",
    "        # prediction = self.classifier(outputs['pooler_output'])\n",
    "        # prediction = F.log_softmax(prediction, -1)\n",
    "        # return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename=None): \n",
    "    # Note: Input model & optimizer should be pre-defined. This routine only updates their states. \n",
    "    start_epoch = 0 \n",
    "    if os.path.isfile(filename): \n",
    "        print(\"=> loading checkpoint '{}'\".format(filename)) \n",
    "        checkpoint = torch.load(filename) \n",
    "        start_epoch = checkpoint['epoch'] \n",
    "        model.load_state_dict(checkpoint['state_dict']) \n",
    "        optimizer.load_state_dict(checkpoint['optimizer']) \n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\" .format(filename,\n",
    "                                                            checkpoint['epoch'])) \n",
    "    else: print(\"=> no checkpoint found at '{}'\".format(filename)) \n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "def mixup_criterion_vqa(criterion, pred_a, pred_b, a_a, a_b, lam):\n",
    "    # print(lam * criterion(pred_a, a_a))\n",
    "    # print((1 - lam) * criterion(pred_b, a_b))\n",
    "    # print(lam * criterion(pred_a, a_a) + (1 - lam) * criterion(pred_b, a_b))\n",
    "    return lam * criterion(pred_a, a_a) + (1 - lam) * criterion(pred_b, a_b)\n",
    "\n",
    "\n",
    "# def accuracy(output, target_a, target_b, lam, topk=(1,)):\n",
    "#     \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "   \n",
    "#     maxk = max(topk)\n",
    "#     batch_size = target_a.size(0)\n",
    "\n",
    "#     _, pred = output.topk(maxk, 1, True, True)\n",
    "#     pred = pred.t()\n",
    "   \n",
    "\n",
    "    \n",
    "#     if target_a.dim() == 2: # multians option\n",
    "#         _, target = torch.max(target, 1)\n",
    "    \n",
    "#     correct_a = pred.eq(target_a.view(1,-1).expand_as(pred))\n",
    "#     correct_b = pred.eq(target_b.view(1,-1).expand_as(pred))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#     # print(pred.eq(target_a))\n",
    "\n",
    "#     # correct += (lam * pred.eq(target_a.data).cpu().sum().float()\n",
    "#     #                 + (1 - lam) * pred.eq(target_b.data).cpu().sum().float())\n",
    "\n",
    "\n",
    "#     res = []\n",
    "#     for k in topk:\n",
    "#         correct_k = lam*correct_a[:k].reshape(-1).float().sum(0) + (1-lam) * correct_b[:k].reshape(-1).float().sum(0)\n",
    "\n",
    "        \n",
    "#         res.append((correct_k / batch_size))\n",
    "   \n",
    "#     return res\n",
    "\n",
    "# def get_bleu_score(predicted, true_ans_a,true_ans_b,lam):\n",
    "#     path_output_change = path_output_chd\n",
    "#     with open(path_output_change+'/answer_classes.json', 'r') as j:\n",
    "#         answer_classes_dict = json.load(j)\n",
    "#     score_a = 0.0\n",
    "#     score_b = 0.0\n",
    "#     assert (len(predicted) == len(true_ans_a))\n",
    "#     assert (len(predicted) == len(true_ans_b))\n",
    "#     ans_keys = list(answer_classes_dict.keys())\n",
    "#     ans_values = list(answer_classes_dict.values())\n",
    "    \n",
    "\n",
    "#     for pred, true_ans in zip(predicted, true_ans_a):\n",
    "#         index_ans = ans_values.index(pred)\n",
    "#         score_a += sentence_bleu([true_ans.split(' ')], ans_keys[index_ans].split(' '), smoothing_function=bleu_score.SmoothingFunction().method2)\n",
    "\n",
    "#     for pred, true_ans in zip(predicted,true_ans_b):\n",
    "#         index_ans = ans_values.index(pred)\n",
    "\n",
    "#         score_b += sentence_bleu([true_ans.split(' ')], ans_keys[index_ans].split(' '), smoothing_function=bleu_score.SmoothingFunction().method2)\n",
    "    \n",
    "\n",
    "#     score = lam * score_a + (1-lam)* score_b\n",
    "    \n",
    "#     return score/len(true_ans_a)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "   \n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "   \n",
    "\n",
    "    \n",
    "    if target.dim() == 2: # multians option\n",
    "        _, target = torch.max(target, 1)\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append((correct_k / batch_size))\n",
    "   \n",
    "    return res\n",
    "\n",
    "def get_bleu_score(predicted, true_ans_text):\n",
    "    path_output_change = path_output_chd\n",
    "    with open(path_output_change+'/answer_classes.json', 'r') as j:\n",
    "        answer_classes_dict = json.load(j)\n",
    "    score = 0.0\n",
    "    assert (len(predicted) == len(true_ans_text))\n",
    "    ans_keys = list(answer_classes_dict.keys())\n",
    "    ans_values = list(answer_classes_dict.values())\n",
    "    \n",
    "\n",
    "    for pred, true_ans in zip(predicted, true_ans_text):\n",
    "        index_ans = ans_values.index(pred)\n",
    "        \n",
    "        score += sentence_bleu([true_ans.split(' ')], ans_keys[index_ans].split(' '), smoothing_function=bleu_score.SmoothingFunction().method2)\n",
    "\n",
    "    return score/len(true_ans_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contrastive_loss(img_emb, txt_emb, margin=0.5):\n",
    "#     pos_score = torch.sum(torch.mul(img_emb, txt_emb), dim=1)\n",
    "#     neg_score = torch.sum(torch.mul(img_emb, torch.roll(txt_emb, shifts=1, dims=0)), dim=1)\n",
    "#     loss = torch.mean(torch.max(torch.zeros_like(pos_score), pos_score - neg_score + margin))\n",
    "#     return loss\n",
    "\n",
    "# def contrastive_loss(img_emb, txt_emb, labels, margin=0.5):\n",
    "#     # Compute dot product between image and text embeddings\n",
    "#     dot_prod = torch.matmul(img_emb, txt_emb.t())\n",
    "#     print('dot_product',labels.shape)\n",
    "#     # Construct positive and negative mask based on label similarity\n",
    "#     pos_mask = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "#     print('pos_mask',pos_mask.shape)\n",
    "#     neg_mask = ~pos_mask\n",
    "#     # Compute positive and negative scores\n",
    "#     pos_score = torch.sum(dot_prod * pos_mask.float(), dim=1)\n",
    "#     neg_score = torch.max(dot_prod * neg_mask.float(), dim=1)[0]\n",
    "#     # Compute loss as hinge loss between positive and negative scores\n",
    "#     loss = torch.mean(torch.max(torch.zeros_like(pos_score), pos_score - neg_score + margin))\n",
    "#     return loss\n",
    "\n",
    "def contrastive_loss(img_emb, txt_emb, margin=0.5):\n",
    "    pos_score = torch.sum(torch.mul(img_emb, txt_emb), dim=1)\n",
    "    neg_score = torch.sum(torch.mul(img_emb, torch.roll(txt_emb, shifts=1, dims=0)), dim=1)\n",
    "    loss = torch.mean(torch.max(torch.zeros_like(pos_score), pos_score - neg_score + margin))\n",
    "    return loss\n",
    "\n",
    "def combined_loss(output, target, img_emb, txt_emb, margin=0.5, ce_weight=0.5):\n",
    "    ce_loss = nn.CrossEntropyLoss()(output, target)\n",
    "    cont_loss = contrastive_loss(img_emb, txt_emb, margin=margin)\n",
    "    # print('cont_loss',cont_loss)\n",
    "    loss = ce_weight * ce_loss + (1-ce_weight) * cont_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "best_acc1 = 0.0\n",
    "best_acc5 = 0.0\n",
    "\n",
    "best_epoch = 0\n",
    "\n",
    "list_train_loss_per_epoch = []\n",
    "list_valid_loss_per_epoch = []\n",
    "\n",
    "list_train_acc1_per_epoch = []\n",
    "list_valid_acc1_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisualBertClassification( opt=opt ).to(device)\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr = opt.INIT_LEARNING_RATE,weight_decay=opt.LAMNDA)\n",
    "\n",
    "input_dir =  path_output_chd \n",
    "input_vqa_train = input_vqa_train \n",
    "input_vqa_valid = input_vqa_valid\n",
    "\n",
    "img_feat_train =  img_feat_train\n",
    "img_feat_valid = img_feat_valid\n",
    "\n",
    "saved_dir =  path_output_chd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = opt.NUM_EPOCHS\n",
    "image_size = opt.IMG_INPUT_SIZE\n",
    "num_workers = 0\n",
    "batch_size = opt.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(\n",
    "        input_dir = input_dir , \n",
    "        input_vqa_train = input_vqa_train, \n",
    "        input_vqa_valid = input_vqa_valid,\n",
    "        img_feat_train = img_feat_train, \n",
    "        img_feat_valid = img_feat_valid,\n",
    "            batch_size = batch_size, \n",
    "            num_workers = num_workers,\n",
    "            size = image_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurag/anaconda3/envs/med_vqa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [01/150], Step[0000/0222], Loss: 3.1893, Top 1 Acc: 0.0000, Top 5 Acc: 0.0312, Bleu: 0.0128\n",
      "| TRAIN SET | Epoch [01/150], Step[0010/0222], Loss: 2.3287, Top 1 Acc: 0.2188, Top 5 Acc: 0.4844, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [01/150], Step[0020/0222], Loss: 2.2713, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0030/0222], Loss: 2.1629, Top 1 Acc: 0.1094, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0040/0222], Loss: 2.0948, Top 1 Acc: 0.0312, Top 5 Acc: 0.5156, Bleu: 0.0364\n",
      "| TRAIN SET | Epoch [01/150], Step[0050/0222], Loss: 2.1522, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0060/0222], Loss: 2.2145, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0070/0222], Loss: 2.0561, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [01/150], Step[0080/0222], Loss: 1.8049, Top 1 Acc: 0.1719, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0090/0222], Loss: 1.9517, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0100/0222], Loss: 1.9660, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0110/0222], Loss: 1.9657, Top 1 Acc: 0.1250, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0120/0222], Loss: 1.8936, Top 1 Acc: 0.2344, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0130/0222], Loss: 1.8824, Top 1 Acc: 0.1719, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0140/0222], Loss: 1.8192, Top 1 Acc: 0.2656, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0150/0222], Loss: 2.0114, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0160/0222], Loss: 1.9543, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0170/0222], Loss: 1.9069, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0180/0222], Loss: 1.9214, Top 1 Acc: 0.0938, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0190/0222], Loss: 1.9878, Top 1 Acc: 0.0781, Top 5 Acc: 0.3438, Bleu: 0.0500\n",
      "| TRAIN SET | Epoch [01/150], Step[0200/0222], Loss: 1.8202, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0210/0222], Loss: 1.8104, Top 1 Acc: 0.2344, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [01/150], Step[0220/0222], Loss: 1.9272, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0372\n",
      "train Loss: 2.0314 Top 1 Acc: 0.1488 Top 5 Acc: 0.4415 Bleu: 0.0117\n",
      "| VALID SET | Epoch [01/150], Step[0000/0031], Loss: 1.9295, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [01/150], Step[0010/0031], Loss: 1.9707, Top 1 Acc: 0.2500, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [01/150], Step[0020/0031], Loss: 2.0787, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| VALID SET | Epoch [01/150], Step[0030/0031], Loss: 1.8929, Top 1 Acc: 0.1562, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "valid Loss: 2.0532 Top 1 Acc: 0.1905 Top 5 Acc: 0.4880 Bleu: 0.0000\n",
      "Epoch 1/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [02/150], Step[0000/0222], Loss: 1.9069, Top 1 Acc: 0.2031, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0010/0222], Loss: 1.9719, Top 1 Acc: 0.1719, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0020/0222], Loss: 1.9779, Top 1 Acc: 0.1250, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0030/0222], Loss: 1.7410, Top 1 Acc: 0.1406, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0040/0222], Loss: 1.7877, Top 1 Acc: 0.1094, Top 5 Acc: 0.5312, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [02/150], Step[0050/0222], Loss: 1.7957, Top 1 Acc: 0.2031, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0060/0222], Loss: 1.9623, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0070/0222], Loss: 1.8241, Top 1 Acc: 0.1406, Top 5 Acc: 0.4844, Bleu: 0.1415\n",
      "| TRAIN SET | Epoch [02/150], Step[0080/0222], Loss: 1.7733, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0090/0222], Loss: 2.0116, Top 1 Acc: 0.1094, Top 5 Acc: 0.4219, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [02/150], Step[0100/0222], Loss: 1.8243, Top 1 Acc: 0.0938, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0110/0222], Loss: 2.0651, Top 1 Acc: 0.0469, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0120/0222], Loss: 1.9356, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0130/0222], Loss: 1.9672, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0140/0222], Loss: 1.9485, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0150/0222], Loss: 2.0124, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0160/0222], Loss: 1.6903, Top 1 Acc: 0.2656, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0170/0222], Loss: 1.9315, Top 1 Acc: 0.1875, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0180/0222], Loss: 1.8347, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0190/0222], Loss: 1.8694, Top 1 Acc: 0.2344, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0200/0222], Loss: 2.0212, Top 1 Acc: 0.1094, Top 5 Acc: 0.3594, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [02/150], Step[0210/0222], Loss: 1.7822, Top 1 Acc: 0.1719, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [02/150], Step[0220/0222], Loss: 1.8599, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "train Loss: 1.8967 Top 1 Acc: 0.1497 Top 5 Acc: 0.4457 Bleu: 0.0078\n",
      "| VALID SET | Epoch [02/150], Step[0000/0031], Loss: 2.0440, Top 1 Acc: 0.1094, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| VALID SET | Epoch [02/150], Step[0010/0031], Loss: 2.1575, Top 1 Acc: 0.0938, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| VALID SET | Epoch [02/150], Step[0020/0031], Loss: 2.1386, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [02/150], Step[0030/0031], Loss: 1.8973, Top 1 Acc: 0.1875, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "valid Loss: 2.0468 Top 1 Acc: 0.1875 Top 5 Acc: 0.4895 Bleu: 0.0000\n",
      "Epoch 2/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [03/150], Step[0000/0222], Loss: 1.8099, Top 1 Acc: 0.1562, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0010/0222], Loss: 1.8256, Top 1 Acc: 0.0938, Top 5 Acc: 0.4531, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [03/150], Step[0020/0222], Loss: 1.9163, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0030/0222], Loss: 1.7320, Top 1 Acc: 0.2031, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0040/0222], Loss: 1.8487, Top 1 Acc: 0.1562, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0050/0222], Loss: 1.9262, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [03/150], Step[0060/0222], Loss: 1.8530, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0070/0222], Loss: 1.9399, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0080/0222], Loss: 1.7691, Top 1 Acc: 0.2344, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0090/0222], Loss: 2.0390, Top 1 Acc: 0.1094, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0100/0222], Loss: 1.7530, Top 1 Acc: 0.3125, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0110/0222], Loss: 1.9651, Top 1 Acc: 0.1875, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0120/0222], Loss: 2.0822, Top 1 Acc: 0.1250, Top 5 Acc: 0.2969, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0130/0222], Loss: 1.8589, Top 1 Acc: 0.1562, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0140/0222], Loss: 1.9143, Top 1 Acc: 0.1719, Top 5 Acc: 0.3438, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [03/150], Step[0150/0222], Loss: 1.6835, Top 1 Acc: 0.1719, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0160/0222], Loss: 1.8284, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0170/0222], Loss: 1.9937, Top 1 Acc: 0.1562, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0180/0222], Loss: 1.7928, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.1022\n",
      "| TRAIN SET | Epoch [03/150], Step[0190/0222], Loss: 1.7444, Top 1 Acc: 0.0781, Top 5 Acc: 0.5312, Bleu: 0.0399\n",
      "| TRAIN SET | Epoch [03/150], Step[0200/0222], Loss: 2.0872, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [03/150], Step[0210/0222], Loss: 2.1108, Top 1 Acc: 0.2188, Top 5 Acc: 0.3594, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [03/150], Step[0220/0222], Loss: 1.9411, Top 1 Acc: 0.1094, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "train Loss: 1.8927 Top 1 Acc: 0.1529 Top 5 Acc: 0.4450 Bleu: 0.0068\n",
      "| VALID SET | Epoch [03/150], Step[0000/0031], Loss: 1.9122, Top 1 Acc: 0.0938, Top 5 Acc: 0.5156, Bleu: 0.1206\n",
      "| VALID SET | Epoch [03/150], Step[0010/0031], Loss: 2.1107, Top 1 Acc: 0.0000, Top 5 Acc: 0.3906, Bleu: 0.0277\n",
      "| VALID SET | Epoch [03/150], Step[0020/0031], Loss: 2.0171, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.1053\n",
      "| VALID SET | Epoch [03/150], Step[0030/0031], Loss: 2.1875, Top 1 Acc: 0.0938, Top 5 Acc: 0.4219, Bleu: 0.0948\n",
      "valid Loss: 2.0588 Top 1 Acc: 0.0900 Top 5 Acc: 0.4720 Bleu: 0.1034\n",
      "Epoch 3/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [04/150], Step[0000/0222], Loss: 1.9828, Top 1 Acc: 0.0469, Top 5 Acc: 0.4219, Bleu: 0.0554\n",
      "| TRAIN SET | Epoch [04/150], Step[0010/0222], Loss: 1.9268, Top 1 Acc: 0.1406, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0020/0222], Loss: 1.9034, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0030/0222], Loss: 1.9099, Top 1 Acc: 0.1250, Top 5 Acc: 0.3750, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [04/150], Step[0040/0222], Loss: 1.9726, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0050/0222], Loss: 1.9215, Top 1 Acc: 0.0938, Top 5 Acc: 0.4062, Bleu: 0.0427\n",
      "| TRAIN SET | Epoch [04/150], Step[0060/0222], Loss: 1.9987, Top 1 Acc: 0.1406, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0070/0222], Loss: 1.9436, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0080/0222], Loss: 1.8256, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0090/0222], Loss: 1.7378, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0100/0222], Loss: 1.9563, Top 1 Acc: 0.0781, Top 5 Acc: 0.3906, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [04/150], Step[0110/0222], Loss: 1.7572, Top 1 Acc: 0.2500, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0120/0222], Loss: 1.9974, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0130/0222], Loss: 1.8436, Top 1 Acc: 0.2344, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0140/0222], Loss: 1.9121, Top 1 Acc: 0.1406, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0150/0222], Loss: 1.8112, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0160/0222], Loss: 1.9249, Top 1 Acc: 0.1875, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0170/0222], Loss: 1.9076, Top 1 Acc: 0.1250, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0180/0222], Loss: 2.0223, Top 1 Acc: 0.1094, Top 5 Acc: 0.3281, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [04/150], Step[0190/0222], Loss: 1.9345, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0200/0222], Loss: 1.7024, Top 1 Acc: 0.2031, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0210/0222], Loss: 1.8197, Top 1 Acc: 0.2188, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [04/150], Step[0220/0222], Loss: 1.9442, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "train Loss: 1.8915 Top 1 Acc: 0.1505 Top 5 Acc: 0.4445 Bleu: 0.0101\n",
      "| VALID SET | Epoch [04/150], Step[0000/0031], Loss: 1.8137, Top 1 Acc: 0.2344, Top 5 Acc: 0.6250, Bleu: 0.0000\n",
      "| VALID SET | Epoch [04/150], Step[0010/0031], Loss: 2.1468, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [04/150], Step[0020/0031], Loss: 1.8234, Top 1 Acc: 0.2031, Top 5 Acc: 0.6250, Bleu: 0.0000\n",
      "| VALID SET | Epoch [04/150], Step[0030/0031], Loss: 2.1047, Top 1 Acc: 0.2031, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "valid Loss: 2.0626 Top 1 Acc: 0.1905 Top 5 Acc: 0.4910 Bleu: 0.0000\n",
      "Epoch 4/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [05/150], Step[0000/0222], Loss: 1.8361, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0010/0222], Loss: 1.7963, Top 1 Acc: 0.2188, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0020/0222], Loss: 1.9267, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0030/0222], Loss: 1.7407, Top 1 Acc: 0.2500, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0040/0222], Loss: 1.9651, Top 1 Acc: 0.1406, Top 5 Acc: 0.4062, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [05/150], Step[0050/0222], Loss: 1.9292, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0060/0222], Loss: 1.6002, Top 1 Acc: 0.2500, Top 5 Acc: 0.5781, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0070/0222], Loss: 1.6544, Top 1 Acc: 0.2344, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0080/0222], Loss: 1.9502, Top 1 Acc: 0.1875, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0090/0222], Loss: 1.8256, Top 1 Acc: 0.1406, Top 5 Acc: 0.5156, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [05/150], Step[0100/0222], Loss: 1.7698, Top 1 Acc: 0.1875, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0110/0222], Loss: 1.8339, Top 1 Acc: 0.1562, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0120/0222], Loss: 1.9620, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [05/150], Step[0130/0222], Loss: 1.8088, Top 1 Acc: 0.1875, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0140/0222], Loss: 1.8810, Top 1 Acc: 0.2031, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0150/0222], Loss: 1.8650, Top 1 Acc: 0.2188, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0160/0222], Loss: 1.7943, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0170/0222], Loss: 1.9365, Top 1 Acc: 0.1875, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0180/0222], Loss: 2.0445, Top 1 Acc: 0.1250, Top 5 Acc: 0.3125, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0190/0222], Loss: 1.9543, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [05/150], Step[0200/0222], Loss: 1.8352, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [05/150], Step[0210/0222], Loss: 2.0287, Top 1 Acc: 0.1406, Top 5 Acc: 0.3750, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [05/150], Step[0220/0222], Loss: 2.0898, Top 1 Acc: 0.0781, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "train Loss: 1.8904 Top 1 Acc: 0.1493 Top 5 Acc: 0.4453 Bleu: 0.0086\n",
      "| VALID SET | Epoch [05/150], Step[0000/0031], Loss: 1.9582, Top 1 Acc: 0.2500, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| VALID SET | Epoch [05/150], Step[0010/0031], Loss: 1.9742, Top 1 Acc: 0.1250, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [05/150], Step[0020/0031], Loss: 1.9358, Top 1 Acc: 0.1250, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [05/150], Step[0030/0031], Loss: 2.0849, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "valid Loss: 2.0277 Top 1 Acc: 0.1965 Top 5 Acc: 0.5045 Bleu: 0.0000\n",
      "Epoch 5/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [06/150], Step[0000/0222], Loss: 1.8525, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0010/0222], Loss: 1.8227, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0020/0222], Loss: 1.8075, Top 1 Acc: 0.1406, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0030/0222], Loss: 1.9443, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0040/0222], Loss: 1.8560, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0050/0222], Loss: 1.6072, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0929\n",
      "| TRAIN SET | Epoch [06/150], Step[0060/0222], Loss: 1.7710, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0070/0222], Loss: 1.8960, Top 1 Acc: 0.2344, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0080/0222], Loss: 1.8779, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0090/0222], Loss: 1.8375, Top 1 Acc: 0.1094, Top 5 Acc: 0.5000, Bleu: 0.0650\n",
      "| TRAIN SET | Epoch [06/150], Step[0100/0222], Loss: 1.9895, Top 1 Acc: 0.1250, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0110/0222], Loss: 2.0421, Top 1 Acc: 0.1406, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0120/0222], Loss: 1.8229, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0130/0222], Loss: 1.9760, Top 1 Acc: 0.0938, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0140/0222], Loss: 1.8204, Top 1 Acc: 0.1094, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0150/0222], Loss: 1.7122, Top 1 Acc: 0.0938, Top 5 Acc: 0.5312, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [06/150], Step[0160/0222], Loss: 1.9053, Top 1 Acc: 0.0938, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0170/0222], Loss: 1.7545, Top 1 Acc: 0.1719, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0180/0222], Loss: 2.0065, Top 1 Acc: 0.0938, Top 5 Acc: 0.3750, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [06/150], Step[0190/0222], Loss: 1.8149, Top 1 Acc: 0.1250, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0200/0222], Loss: 2.0134, Top 1 Acc: 0.0781, Top 5 Acc: 0.3750, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [06/150], Step[0210/0222], Loss: 1.8100, Top 1 Acc: 0.1406, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [06/150], Step[0220/0222], Loss: 1.7485, Top 1 Acc: 0.2031, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "train Loss: 1.8980 Top 1 Acc: 0.1526 Top 5 Acc: 0.4426 Bleu: 0.0119\n",
      "| VALID SET | Epoch [06/150], Step[0000/0031], Loss: 1.9612, Top 1 Acc: 0.2344, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [06/150], Step[0010/0031], Loss: 2.1299, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [06/150], Step[0020/0031], Loss: 2.0495, Top 1 Acc: 0.2031, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [06/150], Step[0030/0031], Loss: 1.9340, Top 1 Acc: 0.2500, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "valid Loss: 2.0460 Top 1 Acc: 0.1905 Top 5 Acc: 0.4925 Bleu: 0.0000\n",
      "Epoch 6/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [07/150], Step[0000/0222], Loss: 1.8136, Top 1 Acc: 0.2344, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0010/0222], Loss: 1.9615, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0020/0222], Loss: 1.9542, Top 1 Acc: 0.1719, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0030/0222], Loss: 1.9300, Top 1 Acc: 0.1094, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0040/0222], Loss: 1.7832, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0050/0222], Loss: 2.0271, Top 1 Acc: 0.0781, Top 5 Acc: 0.3906, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [07/150], Step[0060/0222], Loss: 1.9781, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0070/0222], Loss: 1.8723, Top 1 Acc: 0.2031, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0080/0222], Loss: 1.9923, Top 1 Acc: 0.1406, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0090/0222], Loss: 2.0550, Top 1 Acc: 0.1250, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0100/0222], Loss: 1.8927, Top 1 Acc: 0.2344, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0110/0222], Loss: 2.0143, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0120/0222], Loss: 2.1382, Top 1 Acc: 0.1094, Top 5 Acc: 0.3125, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0130/0222], Loss: 1.8714, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0140/0222], Loss: 1.8060, Top 1 Acc: 0.2031, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0150/0222], Loss: 1.8564, Top 1 Acc: 0.1250, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0160/0222], Loss: 1.8317, Top 1 Acc: 0.1406, Top 5 Acc: 0.4844, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [07/150], Step[0170/0222], Loss: 1.7781, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0180/0222], Loss: 2.0525, Top 1 Acc: 0.1406, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0190/0222], Loss: 1.9091, Top 1 Acc: 0.1094, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0200/0222], Loss: 1.9123, Top 1 Acc: 0.1719, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0210/0222], Loss: 1.9084, Top 1 Acc: 0.2188, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [07/150], Step[0220/0222], Loss: 1.7474, Top 1 Acc: 0.2188, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "train Loss: 1.8898 Top 1 Acc: 0.1556 Top 5 Acc: 0.4462 Bleu: 0.0024\n",
      "| VALID SET | Epoch [07/150], Step[0000/0031], Loss: 2.0241, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [07/150], Step[0010/0031], Loss: 1.9260, Top 1 Acc: 0.2188, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [07/150], Step[0020/0031], Loss: 1.9734, Top 1 Acc: 0.1875, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [07/150], Step[0030/0031], Loss: 1.9578, Top 1 Acc: 0.2031, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "valid Loss: 2.0482 Top 1 Acc: 0.1920 Top 5 Acc: 0.4750 Bleu: 0.0000\n",
      "Epoch 7/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [08/150], Step[0000/0222], Loss: 1.8615, Top 1 Acc: 0.1406, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0010/0222], Loss: 1.7629, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0020/0222], Loss: 1.8567, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0030/0222], Loss: 1.7598, Top 1 Acc: 0.1250, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0040/0222], Loss: 1.7726, Top 1 Acc: 0.2031, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0050/0222], Loss: 1.8619, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0060/0222], Loss: 1.7392, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0070/0222], Loss: 1.8286, Top 1 Acc: 0.2188, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0080/0222], Loss: 1.8829, Top 1 Acc: 0.1094, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0090/0222], Loss: 1.8289, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0100/0222], Loss: 1.8599, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0110/0222], Loss: 1.8151, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [08/150], Step[0120/0222], Loss: 1.9750, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0130/0222], Loss: 1.7096, Top 1 Acc: 0.1719, Top 5 Acc: 0.5625, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [08/150], Step[0140/0222], Loss: 1.7925, Top 1 Acc: 0.1406, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0150/0222], Loss: 1.8856, Top 1 Acc: 0.1875, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0160/0222], Loss: 1.7574, Top 1 Acc: 0.2344, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0170/0222], Loss: 1.9003, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0180/0222], Loss: 1.9841, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0190/0222], Loss: 1.8231, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0200/0222], Loss: 1.9847, Top 1 Acc: 0.0781, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0210/0222], Loss: 1.8434, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [08/150], Step[0220/0222], Loss: 1.7151, Top 1 Acc: 0.2344, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "train Loss: 1.8889 Top 1 Acc: 0.1566 Top 5 Acc: 0.4451 Bleu: 0.0012\n",
      "| VALID SET | Epoch [08/150], Step[0000/0031], Loss: 1.9176, Top 1 Acc: 0.2188, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "| VALID SET | Epoch [08/150], Step[0010/0031], Loss: 2.0842, Top 1 Acc: 0.2500, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| VALID SET | Epoch [08/150], Step[0020/0031], Loss: 1.9377, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| VALID SET | Epoch [08/150], Step[0030/0031], Loss: 1.9960, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "valid Loss: 2.0465 Top 1 Acc: 0.1890 Top 5 Acc: 0.4925 Bleu: 0.0000\n",
      "Epoch 8/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [09/150], Step[0000/0222], Loss: 1.8336, Top 1 Acc: 0.0938, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0010/0222], Loss: 1.7477, Top 1 Acc: 0.1406, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0020/0222], Loss: 1.9013, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0030/0222], Loss: 1.7986, Top 1 Acc: 0.1719, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0040/0222], Loss: 1.8064, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0050/0222], Loss: 1.9813, Top 1 Acc: 0.1719, Top 5 Acc: 0.3594, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [09/150], Step[0060/0222], Loss: 1.7692, Top 1 Acc: 0.1875, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0070/0222], Loss: 1.8863, Top 1 Acc: 0.1250, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0080/0222], Loss: 1.9738, Top 1 Acc: 0.1250, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0090/0222], Loss: 1.9747, Top 1 Acc: 0.0781, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0100/0222], Loss: 1.9993, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [09/150], Step[0110/0222], Loss: 1.6403, Top 1 Acc: 0.1562, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0120/0222], Loss: 2.0502, Top 1 Acc: 0.1094, Top 5 Acc: 0.3594, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [09/150], Step[0130/0222], Loss: 1.8960, Top 1 Acc: 0.0938, Top 5 Acc: 0.3594, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [09/150], Step[0140/0222], Loss: 1.8550, Top 1 Acc: 0.2031, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0150/0222], Loss: 1.9029, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0160/0222], Loss: 1.8229, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0170/0222], Loss: 1.8110, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0372\n",
      "| TRAIN SET | Epoch [09/150], Step[0180/0222], Loss: 1.9789, Top 1 Acc: 0.0781, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0190/0222], Loss: 1.9543, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0200/0222], Loss: 2.0019, Top 1 Acc: 0.1562, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0210/0222], Loss: 1.8529, Top 1 Acc: 0.1250, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [09/150], Step[0220/0222], Loss: 1.7391, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "train Loss: 1.8866 Top 1 Acc: 0.1523 Top 5 Acc: 0.4468 Bleu: 0.0045\n",
      "| VALID SET | Epoch [09/150], Step[0000/0031], Loss: 2.1206, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [09/150], Step[0010/0031], Loss: 2.0385, Top 1 Acc: 0.1719, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [09/150], Step[0020/0031], Loss: 1.9838, Top 1 Acc: 0.1562, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [09/150], Step[0030/0031], Loss: 1.7437, Top 1 Acc: 0.2656, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "valid Loss: 2.0489 Top 1 Acc: 0.1935 Top 5 Acc: 0.4925 Bleu: 0.0000\n",
      "Epoch 9/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [10/150], Step[0000/0222], Loss: 1.8090, Top 1 Acc: 0.1562, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0010/0222], Loss: 1.8517, Top 1 Acc: 0.1875, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0020/0222], Loss: 1.9143, Top 1 Acc: 0.1719, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0030/0222], Loss: 1.7367, Top 1 Acc: 0.1250, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0040/0222], Loss: 1.8050, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0050/0222], Loss: 1.7565, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.1022\n",
      "| TRAIN SET | Epoch [10/150], Step[0060/0222], Loss: 1.8792, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0070/0222], Loss: 1.9339, Top 1 Acc: 0.1250, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0080/0222], Loss: 1.7840, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0090/0222], Loss: 1.9160, Top 1 Acc: 0.1562, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0100/0222], Loss: 2.0141, Top 1 Acc: 0.1094, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0110/0222], Loss: 1.7741, Top 1 Acc: 0.2031, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0120/0222], Loss: 1.6694, Top 1 Acc: 0.2188, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0130/0222], Loss: 1.8834, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0140/0222], Loss: 1.9433, Top 1 Acc: 0.0781, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0150/0222], Loss: 1.8350, Top 1 Acc: 0.1094, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0160/0222], Loss: 1.9089, Top 1 Acc: 0.1875, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0170/0222], Loss: 2.0221, Top 1 Acc: 0.1719, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0180/0222], Loss: 1.8294, Top 1 Acc: 0.2344, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0190/0222], Loss: 1.9655, Top 1 Acc: 0.0781, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0200/0222], Loss: 1.8595, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0210/0222], Loss: 1.7458, Top 1 Acc: 0.1562, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [10/150], Step[0220/0222], Loss: 1.7569, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "train Loss: 1.8876 Top 1 Acc: 0.1550 Top 5 Acc: 0.4477 Bleu: 0.0032\n",
      "| VALID SET | Epoch [10/150], Step[0000/0031], Loss: 1.9644, Top 1 Acc: 0.2188, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [10/150], Step[0010/0031], Loss: 1.9972, Top 1 Acc: 0.1094, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| VALID SET | Epoch [10/150], Step[0020/0031], Loss: 2.1057, Top 1 Acc: 0.1250, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [10/150], Step[0030/0031], Loss: 2.0130, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "valid Loss: 2.0431 Top 1 Acc: 0.1920 Top 5 Acc: 0.4970 Bleu: 0.0000\n",
      "Epoch 10/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [11/150], Step[0000/0222], Loss: 1.8403, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0010/0222], Loss: 1.8335, Top 1 Acc: 0.0625, Top 5 Acc: 0.4375, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [11/150], Step[0020/0222], Loss: 1.9183, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0030/0222], Loss: 1.7958, Top 1 Acc: 0.2031, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0040/0222], Loss: 1.9174, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0050/0222], Loss: 1.8648, Top 1 Acc: 0.0781, Top 5 Acc: 0.4062, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [11/150], Step[0060/0222], Loss: 2.0349, Top 1 Acc: 0.0938, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0070/0222], Loss: 1.8278, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0080/0222], Loss: 1.8963, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0372\n",
      "| TRAIN SET | Epoch [11/150], Step[0090/0222], Loss: 1.8833, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0100/0222], Loss: 1.9132, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0110/0222], Loss: 1.7464, Top 1 Acc: 0.1250, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0120/0222], Loss: 1.8759, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0836\n",
      "| TRAIN SET | Epoch [11/150], Step[0130/0222], Loss: 1.9278, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0140/0222], Loss: 1.8409, Top 1 Acc: 0.1719, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0150/0222], Loss: 1.7832, Top 1 Acc: 0.1719, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0160/0222], Loss: 1.8838, Top 1 Acc: 0.1562, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0170/0222], Loss: 1.8839, Top 1 Acc: 0.1875, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0180/0222], Loss: 1.9073, Top 1 Acc: 0.1250, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0190/0222], Loss: 1.8524, Top 1 Acc: 0.2188, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0200/0222], Loss: 1.8020, Top 1 Acc: 0.2031, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0210/0222], Loss: 1.9578, Top 1 Acc: 0.1406, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [11/150], Step[0220/0222], Loss: 1.9325, Top 1 Acc: 0.1875, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "train Loss: 1.8869 Top 1 Acc: 0.1502 Top 5 Acc: 0.4486 Bleu: 0.0074\n",
      "| VALID SET | Epoch [11/150], Step[0000/0031], Loss: 2.1748, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| VALID SET | Epoch [11/150], Step[0010/0031], Loss: 1.9946, Top 1 Acc: 0.2031, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [11/150], Step[0020/0031], Loss: 1.9130, Top 1 Acc: 0.2500, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| VALID SET | Epoch [11/150], Step[0030/0031], Loss: 1.9923, Top 1 Acc: 0.0938, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "valid Loss: 2.0352 Top 1 Acc: 0.1995 Top 5 Acc: 0.4835 Bleu: 0.0000\n",
      "Epoch 11/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [12/150], Step[0000/0222], Loss: 1.7973, Top 1 Acc: 0.1719, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0010/0222], Loss: 1.6738, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0020/0222], Loss: 2.0003, Top 1 Acc: 0.1094, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0030/0222], Loss: 1.8357, Top 1 Acc: 0.0781, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0040/0222], Loss: 1.8287, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0050/0222], Loss: 1.9274, Top 1 Acc: 0.1875, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0060/0222], Loss: 1.8719, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0070/0222], Loss: 1.8091, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0080/0222], Loss: 1.9914, Top 1 Acc: 0.1250, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0090/0222], Loss: 1.8728, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0100/0222], Loss: 1.7154, Top 1 Acc: 0.2500, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0110/0222], Loss: 1.9662, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0120/0222], Loss: 1.8274, Top 1 Acc: 0.1094, Top 5 Acc: 0.4375, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [12/150], Step[0130/0222], Loss: 1.9766, Top 1 Acc: 0.1719, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0140/0222], Loss: 1.9388, Top 1 Acc: 0.1406, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0150/0222], Loss: 2.0715, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0160/0222], Loss: 1.8448, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0170/0222], Loss: 1.9043, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0180/0222], Loss: 1.8982, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0190/0222], Loss: 1.7624, Top 1 Acc: 0.1250, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0200/0222], Loss: 1.9565, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [12/150], Step[0210/0222], Loss: 1.9960, Top 1 Acc: 0.2188, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [12/150], Step[0220/0222], Loss: 1.9734, Top 1 Acc: 0.0781, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "train Loss: 1.8883 Top 1 Acc: 0.1548 Top 5 Acc: 0.4470 Bleu: 0.0030\n",
      "| VALID SET | Epoch [12/150], Step[0000/0031], Loss: 1.9763, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [12/150], Step[0010/0031], Loss: 2.0822, Top 1 Acc: 0.1250, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [12/150], Step[0020/0031], Loss: 1.7966, Top 1 Acc: 0.2500, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| VALID SET | Epoch [12/150], Step[0030/0031], Loss: 2.0326, Top 1 Acc: 0.1875, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "valid Loss: 2.0421 Top 1 Acc: 0.1935 Top 5 Acc: 0.4975 Bleu: 0.0000\n",
      "Epoch 12/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [13/150], Step[0000/0222], Loss: 1.7690, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0010/0222], Loss: 1.9613, Top 1 Acc: 0.0469, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0020/0222], Loss: 1.9619, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0030/0222], Loss: 1.9648, Top 1 Acc: 0.0781, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0040/0222], Loss: 1.8766, Top 1 Acc: 0.1250, Top 5 Acc: 0.5156, Bleu: 0.0557\n",
      "| TRAIN SET | Epoch [13/150], Step[0050/0222], Loss: 1.7700, Top 1 Acc: 0.1562, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0060/0222], Loss: 1.9015, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0070/0222], Loss: 1.9498, Top 1 Acc: 0.1406, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0080/0222], Loss: 1.8602, Top 1 Acc: 0.1250, Top 5 Acc: 0.5000, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [13/150], Step[0090/0222], Loss: 1.6870, Top 1 Acc: 0.1562, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0100/0222], Loss: 1.8238, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0110/0222], Loss: 2.0060, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0120/0222], Loss: 1.6790, Top 1 Acc: 0.3281, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0130/0222], Loss: 1.8944, Top 1 Acc: 0.1719, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0140/0222], Loss: 1.7757, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0150/0222], Loss: 1.9772, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0160/0222], Loss: 1.9399, Top 1 Acc: 0.0938, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0170/0222], Loss: 1.8493, Top 1 Acc: 0.1094, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0180/0222], Loss: 1.9413, Top 1 Acc: 0.2188, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0190/0222], Loss: 1.8425, Top 1 Acc: 0.2344, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0200/0222], Loss: 1.8027, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0210/0222], Loss: 1.7767, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [13/150], Step[0220/0222], Loss: 2.0299, Top 1 Acc: 0.1250, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "train Loss: 1.8864 Top 1 Acc: 0.1539 Top 5 Acc: 0.4474 Bleu: 0.0039\n",
      "| VALID SET | Epoch [13/150], Step[0000/0031], Loss: 1.8736, Top 1 Acc: 0.1094, Top 5 Acc: 0.5781, Bleu: 0.0000\n",
      "| VALID SET | Epoch [13/150], Step[0010/0031], Loss: 1.9221, Top 1 Acc: 0.2500, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [13/150], Step[0020/0031], Loss: 1.9597, Top 1 Acc: 0.2188, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [13/150], Step[0030/0031], Loss: 1.9320, Top 1 Acc: 0.1406, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "valid Loss: 2.0472 Top 1 Acc: 0.1935 Top 5 Acc: 0.4940 Bleu: 0.0000\n",
      "Epoch 13/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [14/150], Step[0000/0222], Loss: 1.8409, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0010/0222], Loss: 2.0227, Top 1 Acc: 0.0781, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0020/0222], Loss: 1.8273, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0030/0222], Loss: 1.8053, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0040/0222], Loss: 1.7924, Top 1 Acc: 0.2031, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0050/0222], Loss: 1.9806, Top 1 Acc: 0.1875, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0060/0222], Loss: 1.8322, Top 1 Acc: 0.1250, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0070/0222], Loss: 1.9088, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0080/0222], Loss: 2.0414, Top 1 Acc: 0.0781, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0090/0222], Loss: 1.8237, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0100/0222], Loss: 1.8620, Top 1 Acc: 0.1250, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0110/0222], Loss: 1.7428, Top 1 Acc: 0.1875, Top 5 Acc: 0.5781, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0120/0222], Loss: 1.8745, Top 1 Acc: 0.1719, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0130/0222], Loss: 2.0302, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0140/0222], Loss: 1.7928, Top 1 Acc: 0.1250, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0150/0222], Loss: 1.9405, Top 1 Acc: 0.2031, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0160/0222], Loss: 1.8465, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0170/0222], Loss: 1.9316, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0180/0222], Loss: 1.9605, Top 1 Acc: 0.2031, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0190/0222], Loss: 1.8569, Top 1 Acc: 0.1094, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0200/0222], Loss: 2.0658, Top 1 Acc: 0.0781, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0210/0222], Loss: 1.9140, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [14/150], Step[0220/0222], Loss: 1.7837, Top 1 Acc: 0.1406, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "train Loss: 1.8857 Top 1 Acc: 0.1560 Top 5 Acc: 0.4437 Bleu: 0.0002\n",
      "| VALID SET | Epoch [14/150], Step[0000/0031], Loss: 2.0827, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [14/150], Step[0010/0031], Loss: 2.0649, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [14/150], Step[0020/0031], Loss: 2.1582, Top 1 Acc: 0.0938, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [14/150], Step[0030/0031], Loss: 1.8854, Top 1 Acc: 0.2500, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "valid Loss: 2.0426 Top 1 Acc: 0.1890 Top 5 Acc: 0.4945 Bleu: 0.0000\n",
      "Epoch 14/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [15/150], Step[0000/0222], Loss: 1.8821, Top 1 Acc: 0.1875, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0010/0222], Loss: 1.8782, Top 1 Acc: 0.1875, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0020/0222], Loss: 2.0313, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0030/0222], Loss: 1.8966, Top 1 Acc: 0.1094, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0040/0222], Loss: 1.9566, Top 1 Acc: 0.1406, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0050/0222], Loss: 1.7896, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0060/0222], Loss: 2.0243, Top 1 Acc: 0.1250, Top 5 Acc: 0.2656, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0070/0222], Loss: 1.9258, Top 1 Acc: 0.1875, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0080/0222], Loss: 1.8973, Top 1 Acc: 0.2031, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0090/0222], Loss: 1.8975, Top 1 Acc: 0.2188, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0100/0222], Loss: 2.1514, Top 1 Acc: 0.1250, Top 5 Acc: 0.3125, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0110/0222], Loss: 1.6973, Top 1 Acc: 0.2344, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0120/0222], Loss: 2.0967, Top 1 Acc: 0.1094, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0130/0222], Loss: 1.8782, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0140/0222], Loss: 1.8261, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0150/0222], Loss: 1.6669, Top 1 Acc: 0.1250, Top 5 Acc: 0.5625, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [15/150], Step[0160/0222], Loss: 1.8125, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0650\n",
      "| TRAIN SET | Epoch [15/150], Step[0170/0222], Loss: 1.9613, Top 1 Acc: 0.1562, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0180/0222], Loss: 1.7883, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0190/0222], Loss: 1.9280, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0200/0222], Loss: 2.0104, Top 1 Acc: 0.1406, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0210/0222], Loss: 1.6975, Top 1 Acc: 0.2344, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [15/150], Step[0220/0222], Loss: 1.9133, Top 1 Acc: 0.2031, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "train Loss: 1.8866 Top 1 Acc: 0.1553 Top 5 Acc: 0.4460 Bleu: 0.0044\n",
      "| VALID SET | Epoch [15/150], Step[0000/0031], Loss: 2.0287, Top 1 Acc: 0.1094, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| VALID SET | Epoch [15/150], Step[0010/0031], Loss: 2.0101, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [15/150], Step[0020/0031], Loss: 2.0466, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| VALID SET | Epoch [15/150], Step[0030/0031], Loss: 1.9209, Top 1 Acc: 0.2812, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "valid Loss: 2.0441 Top 1 Acc: 0.1905 Top 5 Acc: 0.4970 Bleu: 0.0000\n",
      "Epoch 15/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [16/150], Step[0000/0222], Loss: 1.8754, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0010/0222], Loss: 1.9157, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0020/0222], Loss: 2.0468, Top 1 Acc: 0.1562, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0030/0222], Loss: 1.7730, Top 1 Acc: 0.2344, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0040/0222], Loss: 1.7876, Top 1 Acc: 0.2344, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0050/0222], Loss: 1.7525, Top 1 Acc: 0.2031, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0060/0222], Loss: 1.7686, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0070/0222], Loss: 1.9631, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0080/0222], Loss: 1.7936, Top 1 Acc: 0.2031, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0090/0222], Loss: 1.9798, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0100/0222], Loss: 1.8671, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0110/0222], Loss: 1.7198, Top 1 Acc: 0.2031, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0120/0222], Loss: 1.8119, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0130/0222], Loss: 2.0731, Top 1 Acc: 0.1406, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0140/0222], Loss: 1.8235, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0150/0222], Loss: 1.7784, Top 1 Acc: 0.2031, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0160/0222], Loss: 1.8320, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0170/0222], Loss: 1.6843, Top 1 Acc: 0.2188, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0180/0222], Loss: 1.8819, Top 1 Acc: 0.2031, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0190/0222], Loss: 2.0529, Top 1 Acc: 0.1094, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0200/0222], Loss: 1.8493, Top 1 Acc: 0.1094, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [16/150], Step[0210/0222], Loss: 1.9993, Top 1 Acc: 0.0469, Top 5 Acc: 0.3750, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [16/150], Step[0220/0222], Loss: 1.7807, Top 1 Acc: 0.1562, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "train Loss: 1.8859 Top 1 Acc: 0.1565 Top 5 Acc: 0.4489 Bleu: 0.0027\n",
      "| VALID SET | Epoch [16/150], Step[0000/0031], Loss: 1.9248, Top 1 Acc: 0.2031, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [16/150], Step[0010/0031], Loss: 2.0118, Top 1 Acc: 0.2656, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [16/150], Step[0020/0031], Loss: 2.0253, Top 1 Acc: 0.2188, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [16/150], Step[0030/0031], Loss: 1.9678, Top 1 Acc: 0.2031, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "valid Loss: 2.0451 Top 1 Acc: 0.1875 Top 5 Acc: 0.4925 Bleu: 0.0000\n",
      "Epoch 16/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [17/150], Step[0000/0222], Loss: 1.7300, Top 1 Acc: 0.1719, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0010/0222], Loss: 1.7516, Top 1 Acc: 0.1719, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0020/0222], Loss: 1.8865, Top 1 Acc: 0.1875, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0030/0222], Loss: 1.7998, Top 1 Acc: 0.1875, Top 5 Acc: 0.5312, Bleu: 0.0131\n",
      "| TRAIN SET | Epoch [17/150], Step[0040/0222], Loss: 1.9255, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0050/0222], Loss: 1.8051, Top 1 Acc: 0.1094, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0060/0222], Loss: 1.8601, Top 1 Acc: 0.1719, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0070/0222], Loss: 1.9006, Top 1 Acc: 0.1406, Top 5 Acc: 0.5156, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [17/150], Step[0080/0222], Loss: 1.9302, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0090/0222], Loss: 1.7312, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0100/0222], Loss: 1.7074, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0110/0222], Loss: 1.9650, Top 1 Acc: 0.0938, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0120/0222], Loss: 1.8756, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [17/150], Step[0130/0222], Loss: 2.0221, Top 1 Acc: 0.1406, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0140/0222], Loss: 1.9835, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0150/0222], Loss: 1.8681, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0160/0222], Loss: 2.0911, Top 1 Acc: 0.1562, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0170/0222], Loss: 2.0615, Top 1 Acc: 0.0938, Top 5 Acc: 0.3125, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0180/0222], Loss: 2.0073, Top 1 Acc: 0.1094, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0190/0222], Loss: 1.8383, Top 1 Acc: 0.2500, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0200/0222], Loss: 1.7864, Top 1 Acc: 0.1719, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0210/0222], Loss: 1.9821, Top 1 Acc: 0.1406, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [17/150], Step[0220/0222], Loss: 1.7857, Top 1 Acc: 0.1719, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "train Loss: 1.8855 Top 1 Acc: 0.1558 Top 5 Acc: 0.4473 Bleu: 0.0031\n",
      "| VALID SET | Epoch [17/150], Step[0000/0031], Loss: 1.9100, Top 1 Acc: 0.2031, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| VALID SET | Epoch [17/150], Step[0010/0031], Loss: 2.0517, Top 1 Acc: 0.2031, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [17/150], Step[0020/0031], Loss: 1.8352, Top 1 Acc: 0.2031, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| VALID SET | Epoch [17/150], Step[0030/0031], Loss: 1.9581, Top 1 Acc: 0.1406, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "valid Loss: 2.0381 Top 1 Acc: 0.1905 Top 5 Acc: 0.4985 Bleu: 0.0000\n",
      "Epoch 17/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [18/150], Step[0000/0222], Loss: 1.9096, Top 1 Acc: 0.1250, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0010/0222], Loss: 1.8163, Top 1 Acc: 0.1250, Top 5 Acc: 0.4531, Bleu: 0.0743\n",
      "| TRAIN SET | Epoch [18/150], Step[0020/0222], Loss: 2.0219, Top 1 Acc: 0.1094, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0030/0222], Loss: 1.8093, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0040/0222], Loss: 1.6981, Top 1 Acc: 0.1562, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0050/0222], Loss: 2.1432, Top 1 Acc: 0.1719, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0060/0222], Loss: 1.9111, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0070/0222], Loss: 1.8937, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [18/150], Step[0080/0222], Loss: 1.8272, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0090/0222], Loss: 2.0565, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0100/0222], Loss: 1.9805, Top 1 Acc: 0.1094, Top 5 Acc: 0.3125, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [18/150], Step[0110/0222], Loss: 1.9498, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0120/0222], Loss: 1.9262, Top 1 Acc: 0.1094, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0130/0222], Loss: 1.8536, Top 1 Acc: 0.1406, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0140/0222], Loss: 1.9348, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0150/0222], Loss: 1.7667, Top 1 Acc: 0.1562, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0160/0222], Loss: 2.0655, Top 1 Acc: 0.0312, Top 5 Acc: 0.3125, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0170/0222], Loss: 1.8681, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0180/0222], Loss: 1.9356, Top 1 Acc: 0.1250, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0190/0222], Loss: 1.9818, Top 1 Acc: 0.1562, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0200/0222], Loss: 1.9215, Top 1 Acc: 0.1406, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0210/0222], Loss: 1.9098, Top 1 Acc: 0.1562, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [18/150], Step[0220/0222], Loss: 2.0605, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "train Loss: 1.8848 Top 1 Acc: 0.1543 Top 5 Acc: 0.4452 Bleu: 0.0031\n",
      "| VALID SET | Epoch [18/150], Step[0000/0031], Loss: 2.0040, Top 1 Acc: 0.2344, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| VALID SET | Epoch [18/150], Step[0010/0031], Loss: 2.0891, Top 1 Acc: 0.1875, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [18/150], Step[0020/0031], Loss: 1.9233, Top 1 Acc: 0.2188, Top 5 Acc: 0.5312, Bleu: 0.0000\n",
      "| VALID SET | Epoch [18/150], Step[0030/0031], Loss: 1.9210, Top 1 Acc: 0.2500, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "valid Loss: 2.0412 Top 1 Acc: 0.1920 Top 5 Acc: 0.4940 Bleu: 0.0000\n",
      "Epoch 18/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [19/150], Step[0000/0222], Loss: 1.7925, Top 1 Acc: 0.2500, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0010/0222], Loss: 1.8553, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0020/0222], Loss: 1.8462, Top 1 Acc: 0.1406, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0030/0222], Loss: 1.7976, Top 1 Acc: 0.2031, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0040/0222], Loss: 1.8723, Top 1 Acc: 0.1406, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0050/0222], Loss: 1.8156, Top 1 Acc: 0.2188, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0060/0222], Loss: 1.9086, Top 1 Acc: 0.0938, Top 5 Acc: 0.3438, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0070/0222], Loss: 1.9290, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0080/0222], Loss: 1.7075, Top 1 Acc: 0.1875, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0090/0222], Loss: 2.0403, Top 1 Acc: 0.1094, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0100/0222], Loss: 1.9361, Top 1 Acc: 0.1250, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0110/0222], Loss: 1.9659, Top 1 Acc: 0.1250, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0120/0222], Loss: 1.9890, Top 1 Acc: 0.1094, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0130/0222], Loss: 1.8582, Top 1 Acc: 0.0938, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0140/0222], Loss: 1.7732, Top 1 Acc: 0.1719, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0150/0222], Loss: 1.9302, Top 1 Acc: 0.1875, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0160/0222], Loss: 1.9315, Top 1 Acc: 0.1719, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0170/0222], Loss: 1.8662, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0180/0222], Loss: 1.6995, Top 1 Acc: 0.2031, Top 5 Acc: 0.5469, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0190/0222], Loss: 1.9082, Top 1 Acc: 0.1719, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0200/0222], Loss: 1.9988, Top 1 Acc: 0.1406, Top 5 Acc: 0.3281, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0210/0222], Loss: 1.9266, Top 1 Acc: 0.1406, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [19/150], Step[0220/0222], Loss: 1.8136, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "train Loss: 1.8832 Top 1 Acc: 0.1565 Top 5 Acc: 0.4472 Bleu: 0.0006\n",
      "| VALID SET | Epoch [19/150], Step[0000/0031], Loss: 1.8087, Top 1 Acc: 0.1875, Top 5 Acc: 0.5781, Bleu: 0.0000\n",
      "| VALID SET | Epoch [19/150], Step[0010/0031], Loss: 2.0129, Top 1 Acc: 0.2188, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| VALID SET | Epoch [19/150], Step[0020/0031], Loss: 1.8132, Top 1 Acc: 0.3125, Top 5 Acc: 0.6094, Bleu: 0.0000\n",
      "| VALID SET | Epoch [19/150], Step[0030/0031], Loss: 2.0757, Top 1 Acc: 0.1875, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "valid Loss: 2.0427 Top 1 Acc: 0.1935 Top 5 Acc: 0.4955 Bleu: 0.0000\n",
      "Epoch 19/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [20/150], Step[0000/0222], Loss: 1.7193, Top 1 Acc: 0.2031, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0010/0222], Loss: 1.9744, Top 1 Acc: 0.0625, Top 5 Acc: 0.4219, Bleu: 0.0372\n",
      "| TRAIN SET | Epoch [20/150], Step[0020/0222], Loss: 1.9476, Top 1 Acc: 0.1562, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0030/0222], Loss: 2.0112, Top 1 Acc: 0.0312, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0040/0222], Loss: 1.9591, Top 1 Acc: 0.1250, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0050/0222], Loss: 1.6988, Top 1 Acc: 0.2344, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0060/0222], Loss: 1.9840, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0070/0222], Loss: 1.9641, Top 1 Acc: 0.1250, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0080/0222], Loss: 1.9388, Top 1 Acc: 0.1094, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0090/0222], Loss: 1.9098, Top 1 Acc: 0.1406, Top 5 Acc: 0.5312, Bleu: 0.0279\n",
      "| TRAIN SET | Epoch [20/150], Step[0100/0222], Loss: 2.0390, Top 1 Acc: 0.1406, Top 5 Acc: 0.3750, Bleu: 0.0465\n",
      "| TRAIN SET | Epoch [20/150], Step[0110/0222], Loss: 1.8278, Top 1 Acc: 0.1875, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0120/0222], Loss: 1.7191, Top 1 Acc: 0.2031, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0130/0222], Loss: 1.9395, Top 1 Acc: 0.0938, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0140/0222], Loss: 1.7680, Top 1 Acc: 0.1406, Top 5 Acc: 0.5938, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0150/0222], Loss: 1.8066, Top 1 Acc: 0.1406, Top 5 Acc: 0.4844, Bleu: 0.0186\n",
      "| TRAIN SET | Epoch [20/150], Step[0160/0222], Loss: 1.9428, Top 1 Acc: 0.1250, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0170/0222], Loss: 2.0519, Top 1 Acc: 0.2500, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0180/0222], Loss: 1.8936, Top 1 Acc: 0.1562, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0190/0222], Loss: 1.9210, Top 1 Acc: 0.1875, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0200/0222], Loss: 2.0232, Top 1 Acc: 0.0938, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0210/0222], Loss: 1.9919, Top 1 Acc: 0.1406, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [20/150], Step[0220/0222], Loss: 1.8503, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "train Loss: 1.8839 Top 1 Acc: 0.1546 Top 5 Acc: 0.4497 Bleu: 0.0062\n",
      "| VALID SET | Epoch [20/150], Step[0000/0031], Loss: 2.0617, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| VALID SET | Epoch [20/150], Step[0010/0031], Loss: 1.8309, Top 1 Acc: 0.1719, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| VALID SET | Epoch [20/150], Step[0020/0031], Loss: 2.0189, Top 1 Acc: 0.2656, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| VALID SET | Epoch [20/150], Step[0030/0031], Loss: 1.7672, Top 1 Acc: 0.2188, Top 5 Acc: 0.6094, Bleu: 0.0000\n",
      "valid Loss: 2.0365 Top 1 Acc: 0.1935 Top 5 Acc: 0.4910 Bleu: 0.0000\n",
      "Epoch 20/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [21/150], Step[0000/0222], Loss: 1.8809, Top 1 Acc: 0.1094, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0010/0222], Loss: 1.9345, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0020/0222], Loss: 1.9272, Top 1 Acc: 0.1094, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0030/0222], Loss: 1.9569, Top 1 Acc: 0.1250, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0040/0222], Loss: 1.9389, Top 1 Acc: 0.1562, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0050/0222], Loss: 1.8646, Top 1 Acc: 0.1875, Top 5 Acc: 0.4688, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0060/0222], Loss: 1.7385, Top 1 Acc: 0.2344, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0070/0222], Loss: 1.9340, Top 1 Acc: 0.1250, Top 5 Acc: 0.4375, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0080/0222], Loss: 1.8237, Top 1 Acc: 0.1562, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0090/0222], Loss: 1.7386, Top 1 Acc: 0.1406, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0100/0222], Loss: 1.9214, Top 1 Acc: 0.1562, Top 5 Acc: 0.3750, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0110/0222], Loss: 1.6200, Top 1 Acc: 0.2344, Top 5 Acc: 0.6094, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0120/0222], Loss: 1.7248, Top 1 Acc: 0.1719, Top 5 Acc: 0.5156, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0130/0222], Loss: 1.9538, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0140/0222], Loss: 1.8246, Top 1 Acc: 0.1719, Top 5 Acc: 0.4844, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0150/0222], Loss: 1.8597, Top 1 Acc: 0.0938, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0160/0222], Loss: 1.8999, Top 1 Acc: 0.1406, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0170/0222], Loss: 1.8160, Top 1 Acc: 0.1094, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0180/0222], Loss: 1.9460, Top 1 Acc: 0.1250, Top 5 Acc: 0.3906, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0190/0222], Loss: 1.8630, Top 1 Acc: 0.1094, Top 5 Acc: 0.4219, Bleu: 0.0093\n",
      "| TRAIN SET | Epoch [21/150], Step[0200/0222], Loss: 1.7958, Top 1 Acc: 0.2188, Top 5 Acc: 0.4531, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0210/0222], Loss: 1.8943, Top 1 Acc: 0.1250, Top 5 Acc: 0.4062, Bleu: 0.0000\n",
      "| TRAIN SET | Epoch [21/150], Step[0220/0222], Loss: 1.7816, Top 1 Acc: 0.1406, Top 5 Acc: 0.5625, Bleu: 0.0000\n",
      "train Loss: 1.8843 Top 1 Acc: 0.1581 Top 5 Acc: 0.4479 Bleu: 0.0011\n",
      "| VALID SET | Epoch [21/150], Step[0000/0031], Loss: 1.9903, Top 1 Acc: 0.1094, Top 5 Acc: 0.5000, Bleu: 0.0000\n",
      "| VALID SET | Epoch [21/150], Step[0010/0031], Loss: 2.2295, Top 1 Acc: 0.1562, Top 5 Acc: 0.3594, Bleu: 0.0000\n",
      "| VALID SET | Epoch [21/150], Step[0020/0031], Loss: 2.0016, Top 1 Acc: 0.2500, Top 5 Acc: 0.4219, Bleu: 0.0000\n",
      "| VALID SET | Epoch [21/150], Step[0030/0031], Loss: 2.2831, Top 1 Acc: 0.1094, Top 5 Acc: 0.2969, Bleu: 0.0000\n",
      "valid Loss: 2.0380 Top 1 Acc: 0.1980 Top 5 Acc: 0.4955 Bleu: 0.0000\n",
      "Epoch 21/149\n",
      "----------\n",
      "| TRAIN SET | Epoch [22/150], Step[0000/0222], Loss: 1.8836, Top 1 Acc: 0.1562, Top 5 Acc: 0.4688, Bleu: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.NUM_EPOCHS):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        top1_acc=0\n",
    "        top5_acc=0\n",
    "        bleu=0\n",
    "\n",
    "        batch_step_size = len(data_loader[phase].dataset) / batch_size\n",
    "        \n",
    "        for batch_idx, batch_sample in enumerate(data_loader[phase]):\n",
    "            # print('batch_sample',batch_sample.keys())\n",
    "            question = batch_sample['question']\n",
    "            answer = batch_sample['answer']\n",
    "            labels = batch_sample['label'].to(device)\n",
    "            # label_answer_text = batch_sample['answer_text']\n",
    "            image = batch_sample['image_feature'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                logits,img_emb,text_emb = model(image,question)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                # loss = contrastive_loss(img_emb,text_emb,labels)\n",
    "                loss = combined_loss(logits, labels, img_emb, text_emb)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            acc1,acc5 = accuracy(logits.data, labels.data, topk=(1, 5))\n",
    "            top1_acc += acc1\n",
    "            top5_acc += acc5\n",
    "            #bleu score\n",
    "            b = get_bleu_score(preds, answer)\n",
    "            bleu += b\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('| {} SET | Epoch [{:02d}/{:02d}], Step[{:04d}/{:04d}], Loss: {:.4f}, Top 1 Acc: {:.4f}, Top 5 Acc: {:.4f}, Bleu: {:.4f}'.format(phase.upper(), epoch+1, num_epochs, batch_idx, int(batch_step_size), loss.item(), acc1, acc5, b))#Acc: {:.4f},Bleu: {:.4f},acc, b\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss/batch_step_size\n",
    "        epoch_acc1 = top1_acc/batch_step_size\n",
    "        epoch_acc5 = top5_acc/batch_step_size\n",
    "        \n",
    "        epoch_blue = bleu/batch_step_size\n",
    "\n",
    "        #save the loss and accuracy for train and valid\n",
    "        if phase =='train':\n",
    "            list_train_loss_per_epoch.append(epoch_loss)\n",
    "            list_train_acc1_per_epoch.append(epoch_acc1)\n",
    "        else:\n",
    "            list_valid_loss_per_epoch.append(epoch_loss)\n",
    "            list_valid_acc1_per_epoch.append(epoch_acc1)\n",
    "\n",
    "        print('{} Loss: {:.4f} Top 1 Acc: {:.4f} Top 5 Acc: {:.4f} Bleu: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc1,epoch_acc5, epoch_blue))\n",
    "            \n",
    "        # deep copy the model\n",
    "        if phase == 'valid' and epoch_acc1 > best_acc1: #or epoch_acc5 > best_acc5 ):\n",
    "            best_acc1 = epoch_acc1\n",
    "            best_acc5 = epoch_acc5\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(history, epoch_max, path_output_chd, type_plot='loss'):\n",
    "    train = history['train']\n",
    "    valid = history['valid']\n",
    "    fig, ax = plt.subplots()\n",
    "    epochs = range(epoch_max)\n",
    "    \n",
    "    \n",
    "    if type_plot=='loss':\n",
    "        plt.plot(epochs, train, '-r', lw=2, label='Training loss')\n",
    "        plt.plot(epochs, valid, '-b',lw=2, label='validation loss')\n",
    "        plt.legend(borderaxespad=0.)\n",
    "        plt.title('Training and Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig(path_output_chd+'/imgs/loss.png')\n",
    "        \n",
    "    elif type_plot == 'acc1':\n",
    "        ltrain = []\n",
    "        lvalid = []\n",
    "        for i in range(len(train)):\n",
    "            ltrain.append(train[i].to('cpu').numpy().tolist())\n",
    "        for i in range(len(valid)):\n",
    "            lvalid.append(valid[i].to('cpu').numpy().tolist())\n",
    "    \n",
    "        plt.plot(epochs, ltrain, '-r', lw = 2, label='Training Top 1 Accuracy')\n",
    "        plt.plot(epochs, lvalid, '-b', lw = 2, label='validation Top 1 Accuracy')\n",
    "        plt.legend(borderaxespad=0.)\n",
    "        plt.title('Training and Validation Top 1 Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Top 1 Accuracy')\n",
    "        plt.savefig(path_output_chd+'/imgs/acc1.png')\n",
    "\n",
    "    elif type_plot == 'acc5':\n",
    "        ltrain = []\n",
    "        lvalid = []\n",
    "        for i in range(len(train)):\n",
    "            ltrain.append(train[i].to('cpu').numpy().tolist())\n",
    "        for i in range(len(valid)):\n",
    "            lvalid.append(valid[i].to('cpu').numpy().tolist())\n",
    "        plt.plot(epochs, ltrain, '-r', lw = 2, label='Training Top 5 Accuracy')\n",
    "        plt.plot(epochs, lvalid, '-b', lw = 2, label='validation Top 5 Accuracy')\n",
    "        plt.legend(borderaxespad=0.)\n",
    "        plt.title('Training and Validation Top 5 Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Top 5 Accuracy')\n",
    "        plt.savefig(path_output_chd+'/imgs/acc5.png')\n",
    "    else:\n",
    "        ltrain = []\n",
    "        lvalid = []\n",
    "        for i in range(len(train)):\n",
    "            ltrain.append(train[i].to('cpu').numpy().tolist())\n",
    "        for i in range(len(valid)):\n",
    "            lvalid.append(valid[i].to('cpu').numpy().tolist())\n",
    "        plt.plot(epochs, ltrain, '-r', lw = 2, label='Training blue')\n",
    "        plt.plot(epochs, lvalid, '-b', lw = 2, label='validation blue')\n",
    "        plt.legend(borderaxespad=0.)\n",
    "        plt.title('Training and Validation blue')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Blue')\n",
    "        plt.savefig(path_output_chd+'/imgs/blue.png')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 153m 24s\n",
      "Best val Top 1 Acc: 0.721500, Top 5 Acc: 0.946000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_loss = {'train':list_train_loss_per_epoch, 'valid':list_valid_loss_per_epoch}\n",
    "history_acc1 = {'train':list_train_acc1_per_epoch, 'valid':list_valid_acc1_per_epoch}\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Top 1 Acc: {:4f}, Top 5 Acc: {:4f}'.format(best_acc1,best_acc5))\n",
    "\n",
    "#plot the loss and accuracy for train and valid\n",
    "make_plot(history_loss, num_epochs, input_dir, type_plot='loss')\n",
    "make_plot(history_acc1, num_epochs,input_dir, type_plot='acc1')\n",
    "\n",
    "\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "model.load_state_dict(best_model_wts)\n",
    "state = {'epoch': best_epoch, \n",
    "        'state_dict': model.state_dict(), \n",
    "        'optimizer': optimizer.state_dict(), \n",
    "            'loss':epoch_loss,'valid_accuracy': best_acc1}\n",
    "\n",
    "full_model_path =saved_dir+'/mixed_model_state_seed_97.tar'\n",
    "\n",
    "torch.save(state, full_model_path)\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa = np.load('/home/arunava/VQA_Med/test_dataset_pickle/test19_df.pkl', allow_pickle=True )\n",
    "\n",
    "input_test = 'test_dataset_pickle/test_dataset_df.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>PATH</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synpic54733</td>\n",
       "      <td>what imaging modality was used to take this im...</td>\n",
       "      <td>ct with iv contrast</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synpic25647</td>\n",
       "      <td>what kind of scan is this?</td>\n",
       "      <td>xr - plain film</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synpic35681</td>\n",
       "      <td>was the mri taken with contrast?</td>\n",
       "      <td>no</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synpic39641</td>\n",
       "      <td>is this a t1 weighted, t2 weighted, or flair i...</td>\n",
       "      <td>t2</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synpic35693</td>\n",
       "      <td>is this a noncontrast mri?</td>\n",
       "      <td>yes</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>synpic45828</td>\n",
       "      <td>what is abnormal in the mri?</td>\n",
       "      <td>marked hydrocephalus due to aqueductal stenosis</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>synpic60458</td>\n",
       "      <td>what is abnormal in the x-ray?</td>\n",
       "      <td>discoid meniscus</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>synpic43524</td>\n",
       "      <td>what is most alarming about this mri?</td>\n",
       "      <td>choroid plexus neoplasm, papilloma, carcinoma</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>synpic59568</td>\n",
       "      <td>what is abnormal in the mri?</td>\n",
       "      <td>multiple sclerosis</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>synpic48459</td>\n",
       "      <td>what is most alarming about this mri?</td>\n",
       "      <td>spine,  tethered  cord</td>\n",
       "      <td>/home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID                                                  Q  \\\n",
       "0     synpic54733  what imaging modality was used to take this im...   \n",
       "1     synpic25647                         what kind of scan is this?   \n",
       "2     synpic35681                   was the mri taken with contrast?   \n",
       "3     synpic39641  is this a t1 weighted, t2 weighted, or flair i...   \n",
       "4     synpic35693                         is this a noncontrast mri?   \n",
       "...           ...                                                ...   \n",
       "1995  synpic45828                       what is abnormal in the mri?   \n",
       "1996  synpic60458                     what is abnormal in the x-ray?   \n",
       "1997  synpic43524              what is most alarming about this mri?   \n",
       "1998  synpic59568                       what is abnormal in the mri?   \n",
       "1999  synpic48459              what is most alarming about this mri?   \n",
       "\n",
       "                                                    A  \\\n",
       "0                                 ct with iv contrast   \n",
       "1                                     xr - plain film   \n",
       "2                                                  no   \n",
       "3                                                  t2   \n",
       "4                                                 yes   \n",
       "...                                               ...   \n",
       "1995  marked hydrocephalus due to aqueductal stenosis   \n",
       "1996                                 discoid meniscus   \n",
       "1997    choroid plexus neoplasm, papilloma, carcinoma   \n",
       "1998                               multiple sclerosis   \n",
       "1999                           spine,  tethered  cord   \n",
       "\n",
       "                                                   PATH  labels  \n",
       "0     /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...      33  \n",
       "1     /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...       5  \n",
       "2     /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...       2  \n",
       "3     /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...      12  \n",
       "4     /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...       3  \n",
       "...                                                 ...     ...  \n",
       "1995  /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...     177  \n",
       "1996  /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...     177  \n",
       "1997  /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...     127  \n",
       "1998  /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...      62  \n",
       "1999  /home/arunava/VQA_Med/data/raw/ImageCLEF/val_2...     177  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_test_loader(input_dir,input_test, img_feat_vqa,batch_size, num_workers,size=228):\n",
    "    test_vqa_dataset = VqaDataset(\n",
    "            input_dir=input_dir,\n",
    "            input_vqa=input_test,\n",
    "            img_feat_vqa=img_feat_vqa,\n",
    "            phase = 'test')\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=test_vqa_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=num_workers)\n",
    "    return data_loader\n",
    "\n",
    "batch_size = opt.BATCH_SIZE\n",
    "num_workers = 0\n",
    "image_size = opt.IMG_INPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imput_test test_dataset_pickle/test_dataset_df.pkl\n"
     ]
    }
   ],
   "source": [
    "print('imput_test',input_test)\n",
    "# Create the DataLoader for our dataset\n",
    "test_data_loader = get_test_loader(\n",
    "    input_dir = input_dir , \n",
    "    input_test = input_test, \n",
    "    img_feat_vqa = img_feat_test,\n",
    "    batch_size = batch_size, \n",
    "    num_workers = num_workers,\n",
    "    size = image_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisualBertClassification(\n",
       "  (model): VisualBertModel(\n",
       "    (embeddings): VisualBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (visual_token_type_embeddings): Embedding(2, 768)\n",
       "      (visual_position_embeddings): Embedding(512, 768)\n",
       "      (visual_projection): Linear(in_features=1984, out_features=768, bias=True)\n",
       "    )\n",
       "    (encoder): VisualBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): VisualBertLayer(\n",
       "          (attention): VisualBertAttention(\n",
       "            (self): VisualBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): VisualBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): VisualBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): VisualBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): VisualBertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_text): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (linear_img): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=178, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_res = None\n",
    "path_change = '/home/arunava'\n",
    "\n",
    "since = time.time()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "res={'Image_id':[],'Answer':[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_sample {'image_feature': tensor([[[5.0509e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.8783e-02],\n",
      "         ...,\n",
      "         [4.8391e-03],\n",
      "         [1.2388e-04],\n",
      "         [8.9071e-05]],\n",
      "\n",
      "        [[4.1791e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.7559e-02],\n",
      "         ...,\n",
      "         [7.8599e-03],\n",
      "         [2.6479e-03],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[8.4814e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.6439e-02],\n",
      "         ...,\n",
      "         [1.1273e-03],\n",
      "         [3.7918e-05],\n",
      "         [4.1715e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.2584e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.8843e-02],\n",
      "         ...,\n",
      "         [2.6486e-03],\n",
      "         [7.8198e-05],\n",
      "         [2.3279e-04]],\n",
      "\n",
      "        [[5.0712e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.8258e-02],\n",
      "         ...,\n",
      "         [4.2934e-03],\n",
      "         [5.2815e-03],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[6.3775e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.5576e-02],\n",
      "         ...,\n",
      "         [2.2388e-03],\n",
      "         [8.3069e-03],\n",
      "         [7.8251e-04]]]), 'image_id': ['synpic54082', 'synpic48556', 'synpic50696', 'synpic37194', 'synpic31308', 'synpic24739', 'synpic32365', 'synpic47936', 'synpic29792', 'synpic43561', 'synpic40732', 'synpic33904', 'synpic39583', 'synpic39568', 'synpic27024', 'synpic25155', 'synpic52493', 'synpic53941', 'synpic58343', 'synpic48150', 'synpic26892', 'synpic48805', 'synpic41996', 'synpic52901', 'synpic26702', 'synpic36075', 'synpic15874', 'synpic28538', 'synpic45924', 'synpic24458', 'synpic34139', 'synpic58746', 'synpic36276', 'synpic46949', 'synpic60018', 'synpic14955', 'synpic38267', 'synpic18809', 'synpic55706', 'synpic51206', 'synpic46829', 'synpic24706', 'synpic22377', 'synpic43979', 'synpic32831', 'synpic33285', 'synpic55100', 'synpic48384', 'synpic59289', 'synpic54975', 'synpic51170', 'synpic40069', 'synpic51160', 'synpic18560', 'synpic51606', 'synpic19859', 'synpic27747', 'synpic13384', 'synpic59702', 'synpic60197', 'synpic56425', 'synpic33295', 'synpic43772', 'synpic56394'], 'question': ['what modality is shown? ', 'was the mri taken with contrast? ', 'what type of contrast did this patient have? ', 'what imaging method was used? ', 'what modality is shown? ', 'what is the mr weighting in this image? ', 'is this a ct scan? ', 'what type of contrast did this patient have? ', 'was iv contrast given to the patient? ', 'was the ct scan taken with contrast? ', 'what imaging modality was used to take this image? ', 'was the ct scan taken with contrast? ', 'is this a noncontrast mri? ', 'what type of image modality is seen? ', 'is this a ct scan? ', 'is this image modality t1, t2, or flair? ', 'what type of imaging is this? ', 'what imaging modality was used to take this image? ', 'what imaging modality was used to take this image? ', 'was the ct scan taken with contrast? ', 'was gi contrast given to the patient? ', 'was the ct scan taken with contrast? ', 'is this a noncontrast mri? ', 'is this a t1 weighted, t2 weighted, or flair image? ', 'is this an mri image? ', 'is this a ct scan? ', 'is this a noncontrast ct? ', 'what modality is shown? ', 'which image modality is this? ', 'what imaging modality was used to take this image? ', 'what was this image taken with? ', 'is this a contrast or noncontrast ct? ', 'is this a t1 weighted image? ', 'what imaging modality is used to acquire this picture? ', 'is this image modality t1, t2, or flair? ', 'what type of imaging modality is shown? ', 'was the mri taken with contrast? ', 'what type of imaging modality is shown? ', 'is this a t2 weighted image? ', 'is this an mri image? ', 'is this a noncontrast ct? ', 'was gi contrast given to the patient? ', 'what imaging modality is used? ', 'what imaging modality is used to acquire this picture? ', 'is this a noncontrast ct? ', 'was the ct scan taken with contrast? ', 'was the ct scan taken with contrast? ', 'what type of imaging does this represent? ', 'what type of contrast did this patient have? ', 'is this a noncontrast mri? ', 'was the ct scan taken with contrast? ', 'is this a contrast or noncontrast ct? ', 'how was the image taken? ', 'is this a contrast or noncontrast ct? ', 'what kind of scan is this? ', 'what type of imaging modality is seen in this image? ', 'is this a noncontrast ct? ', 'what type of image modality is seen? ', 'is this a noncontrast mri? ', 'was iv contrast given to the patient? ', 'what type of image modality is seen? ', 'what modality was used to take this image? ', 'is this a ct scan? ', 'what imaging modality was used to take this image? ']}\n",
      "batch_sample {'image_feature': tensor([[[4.7868e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3735e-02],\n",
      "         ...,\n",
      "         [1.2385e-03],\n",
      "         [6.6456e-03],\n",
      "         [7.7635e-04]],\n",
      "\n",
      "        [[7.8656e-03],\n",
      "         [3.1839e-08],\n",
      "         [1.4690e-02],\n",
      "         ...,\n",
      "         [1.3386e-03],\n",
      "         [2.5788e-04],\n",
      "         [1.6098e-05]],\n",
      "\n",
      "        [[4.9899e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3574e-02],\n",
      "         ...,\n",
      "         [8.2510e-04],\n",
      "         [1.7177e-03],\n",
      "         [5.3433e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.5914e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.6085e-02],\n",
      "         ...,\n",
      "         [3.6859e-04],\n",
      "         [0.0000e+00],\n",
      "         [6.6149e-04]],\n",
      "\n",
      "        [[9.5517e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.9256e-02],\n",
      "         ...,\n",
      "         [1.0937e-03],\n",
      "         [4.5215e-04],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[4.3725e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.8121e-02],\n",
      "         ...,\n",
      "         [4.2288e-03],\n",
      "         [4.8983e-04],\n",
      "         [0.0000e+00]]]), 'image_id': ['synpic33518', 'synpic28138', 'synpic31469', 'synpic35155', 'synpic40333', 'synpic41011', 'synpic51202', 'synpic44800', 'synpic59851', 'synpic35747', 'synpic54150', 'synpic25024', 'synpic34128', 'synpic45935', 'synpic19086', 'synpic35578', 'synpic51767', 'synpic27197', 'synpic44430', 'synpic46964', 'synpic41979', 'synpic32773', 'synpic31285', 'synpic40440', 'synpic22366', 'synpic100408', 'synpic50733', 'synpic49262', 'synpic27752', 'synpic53951', 'synpic24501', 'synpic52497', 'synpic47924', 'synpic22825', 'synpic18213', 'synpic34909', 'synpic56154', 'synpic39585', 'synpic16994', 'synpic51407', 'synpic37609', 'synpic27432', 'synpic28715', 'synpic53600', 'synpic40697', 'synpic41589', 'synpic24310', 'synpic51770', 'synpic47890', 'synpic40127', 'synpic37634', 'synpic26922', 'synpic37740', 'synpic28890', 'synpic49513', 'synpic52133', 'synpic24258', 'synpic21334', 'synpic45842', 'synpic37595', 'synpic55335', 'synpic56130', 'synpic21435', 'synpic39252'], 'question': ['is this a contrast or noncontrast mri? ', 'was the ct scan taken with contrast? ', 'is this a contrast or noncontrast ct? ', 'what imaging modality was used to take this image? ', 'how was this image taken? ', 'is this a t2 weighted image? ', 'what imaging modality was used to take this image? ', 'is this a contrast or noncontrast ct? ', 'how was this image taken? ', 'what imaging modality was used to take this image? ', 'what imaging modality was used to take this image? ', 'is this a ct scan? ', 'what type of imaging modality is seen in this image? ', 'is this a contrast or noncontrast ct? ', 'what imaging modality was used to take this image? ', 'is this a noncontrast mri? ', 'what imaging modality was used to take this image? ', 'was gi contrast given to the patient? ', 'is this a contrast or noncontrast mri? ', 'with what modality is this image taken? ', 'what type of imaging modality is shown? ', 'what type of image modality is this? ', 'is this an mri image? ', 'was gi contrast given to the patient? ', 'which image modality is this? ', 'what type of image modality is this? ', 'is this a noncontrast ct? ', 'is this a t2 weighted image? ', 'what imaging modality is used to acquire this picture? ', 'was the mri taken with contrast? ', 'what type of imaging modality is shown? ', 'is this a t2 weighted image? ', 'what type of imaging modality is used to acquire the image? ', 'what imaging modality was used to take this image? ', 'what imaging method was used? ', 'is this a noncontrast mri? ', 'is this a t1 weighted image? ', 'is this a t1 weighted, t2 weighted, or flair image? ', 'is this a t1 weighted, t2 weighted, or flair image? ', 'is this a ct scan? ', 'what modality is shown? ', 'what type of imaging modality is shown? ', 'was the ct scan taken with contrast? ', 'is this a t2 weighted image? ', 'is this a ct scan? ', 'what imaging modality was used to take this image? ', 'is this a noncontrast ct? ', 'was gi contrast given to the patient? ', 'what imaging modality was used to take this image? ', 'what is the mr weighting in this image? ', 'is this a noncontrast mri? ', 'what type of imaging modality is shown? ', 'is this a t1 weighted, t2 weighted, or flair image? ', 'is this a contrast or noncontrast ct? ', 'what imaging modality was used to take this image? ', 'what kind of scan is this? ', 'is this a ct scan? ', 'is this an mri image? ', 'is this a t1 weighted image? ', 'what type of imaging modality is shown? ', 'is this an mri image? ', 'what is the plane of the ct scan? ', 'in what plane is this ct scan? ', 'what imaging plane is depicted here? ']}\n",
      "batch_sample {'image_feature': tensor([[[0.0063],\n",
      "         [0.0000],\n",
      "         [0.0110],\n",
      "         ...,\n",
      "         [0.0006],\n",
      "         [0.0005],\n",
      "         [0.0113]],\n",
      "\n",
      "        [[0.0041],\n",
      "         [0.0000],\n",
      "         [0.0160],\n",
      "         ...,\n",
      "         [0.0061],\n",
      "         [0.0056],\n",
      "         [0.0003]],\n",
      "\n",
      "        [[0.0151],\n",
      "         [0.0000],\n",
      "         [0.0178],\n",
      "         ...,\n",
      "         [0.0009],\n",
      "         [0.0006],\n",
      "         [0.0014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0073],\n",
      "         [0.0000],\n",
      "         [0.0223],\n",
      "         ...,\n",
      "         [0.0028],\n",
      "         [0.0006],\n",
      "         [0.0002]],\n",
      "\n",
      "        [[0.0056],\n",
      "         [0.0000],\n",
      "         [0.0141],\n",
      "         ...,\n",
      "         [0.0040],\n",
      "         [0.0008],\n",
      "         [0.0028]],\n",
      "\n",
      "        [[0.0066],\n",
      "         [0.0000],\n",
      "         [0.0190],\n",
      "         ...,\n",
      "         [0.0057],\n",
      "         [0.0019],\n",
      "         [0.0035]]]), 'image_id': ['synpic23785', 'synpic58323', 'synpic51449', 'synpic39087', 'synpic16716', 'synpic54525', 'synpic38372', 'synpic39865', 'synpic58519', 'synpic26986', 'synpic58294', 'synpic24161', 'synpic26010', 'synpic36217', 'synpic56736', 'synpic44454', 'synpic54653', 'synpic56044', 'synpic21569', 'synpic59376', 'synpic55564', 'synpic34367', 'synpic48079', 'synpic35657', 'synpic27290', 'synpic29040', 'synpic27737', 'synpic39290', 'synpic27906', 'synpic58863', 'synpic46888', 'synpic20264', 'synpic38359', 'synpic36374', 'synpic41842', 'synpic21783', 'synpic57403', 'synpic17769', 'synpic59360', 'synpic15817', 'synpic51932', 'synpic32067', 'synpic16112', 'synpic39867', 'synpic35132', 'synpic28605', 'synpic56442', 'synpic52142', 'synpic51311', 'synpic41102', 'synpic37080', 'synpic54719', 'synpic43507', 'synpic58325', 'synpic55832', 'synpic43936', 'synpic61201', 'synpic18885', 'synpic44136', 'synpic16894', 'synpic51261', 'synpic34406', 'synpic41927', 'synpic50433'], 'question': ['what is the plane of the ct scan? ', 'in what plane is this mri captured? ', 'which plane is the image taken? ', 'what image plane is this? ', 'which plane is the image shown in? ', 'in what plane was this image taken? ', 'in what plane is this ct scan? ', 'what imaging plane is depicted here? ', 'what plane was used in this ct scan? ', 'in what plane is this image taken? ', 'in which plane is the mri displayed? ', 'which plane is this image in? ', 'what plane is this? ', 'what plane is the image acquired in? ', 'what plane is this mri in? ', 'what plane was used in this ct scan? ', 'in what plane is this mri? ', 'which plane is this image taken? ', 'what plane is this? ', 'in what plane is this image taken? ', 'in what plane was this image taken? ', 'in what plane is this image oriented? ', 'what plane is this film ', 'in what plane is this x-ray? ', 'which plane is this mri taken in? ', 'in what plane is this image oriented? ', 'what is the plane of this x-ray? ', 'which plane is the image taken? ', 'in what plane is this image taken? ', 'in what plane is this ct scan? ', 'which plane is this image in? ', 'which plane is this image in? ', 'what is the plane of the image? ', 'what plane was used? ', 'in what plane is this image taken? ', 'what plane is this? ', 'what image plane is this? ', 'what imaging plane is depicted here? ', 'in what plane is this angiogram taken? ', 'what is the plane? ', 'what is the plane of the image? ', 'what plane was used? ', 'what plane is the image acquired in? ', 'in which plane is the mri displayed? ', 'what image plane is this? ', 'what is the plane of the image? ', 'what plane is demonstrated? ', 'in what plane is this mri taken? ', 'what plane is this ct scan in? ', 'what is the plane? ', 'what plane is demonstrated? ', 'in what plane is this image taken? ', 'in which plane is the x-ray displayed? ', 'what imaging plane is depicted here? ', 'in what plane is this image taken? ', 'what plane was used in this ct scan? ', 'in what plane is this ultrasound? ', 'what plane is this? ', 'what plane is the image acquired in? ', 'what is the plane of the ct scan? ', 'in what plane was this image taken? ', 'which plane is this image taken? ', 'in what plane is this image oriented? ', 'what imaging plane is depicted here? ']}\n",
      "batch_sample {'image_feature': tensor([[[4.4639e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.6040e-02],\n",
      "         ...,\n",
      "         [4.4107e-03],\n",
      "         [4.0535e-04],\n",
      "         [7.4602e-06]],\n",
      "\n",
      "        [[4.4558e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.5171e-02],\n",
      "         ...,\n",
      "         [8.5226e-03],\n",
      "         [5.3539e-04],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[3.9856e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3943e-02],\n",
      "         ...,\n",
      "         [7.2175e-03],\n",
      "         [1.1809e-03],\n",
      "         [3.4381e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.3538e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.5577e-02],\n",
      "         ...,\n",
      "         [6.2175e-03],\n",
      "         [2.4122e-03],\n",
      "         [4.2517e-04]],\n",
      "\n",
      "        [[2.6953e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.9207e-02],\n",
      "         ...,\n",
      "         [3.6050e-04],\n",
      "         [7.8263e-04],\n",
      "         [4.9246e-04]],\n",
      "\n",
      "        [[5.4736e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.0452e-02],\n",
      "         ...,\n",
      "         [2.1314e-03],\n",
      "         [2.9428e-03],\n",
      "         [2.0277e-04]]]), 'image_id': ['synpic26566', 'synpic53852', 'synpic41503', 'synpic45003', 'synpic25536', 'synpic41932', 'synpic20466', 'synpic16881', 'synpic52027', 'synpic32894', 'synpic35645', 'synpic27282', 'synpic37250', 'synpic27725', 'synpic17194', 'synpic21397', 'synpic52423', 'synpic42156', 'synpic51894', 'synpic38836', 'synpic54736', 'synpic53065', 'synpic43510', 'synpic53717', 'synpic60336', 'synpic8584', 'synpic43048', 'synpic27294', 'synpic28170', 'synpic100253', 'synpic37124', 'synpic54130', 'synpic27647', 'synpic41919', 'synpic57835', 'synpic23193', 'synpic27256', 'synpic32897', 'synpic53299', 'synpic32698', 'synpic49799', 'synpic60451', 'synpic51667', 'synpic53064', 'synpic59213', 'synpic53981', 'synpic53995', 'synpic59260', 'synpic56806', 'synpic55670', 'synpic23916', 'synpic47328', 'synpic50132', 'synpic28076', 'synpic44351', 'synpic24314', 'synpic31739', 'synpic25598', 'synpic16333', 'synpic53848', 'synpic31015', 'synpic56918', 'synpic26227', 'synpic31996'], 'question': ['what plane is seen? ', 'in what plane is this ct scan? ', 'which plane is the image shown in? ', 'in what plane is this mri? ', 'what plane was used? ', 'what is the plane of this ct scan? ', 'what is the plane of this mri? ', 'in which plane is the x-ray displayed? ', 'what is the plane? ', 'in what plane is this x-ray taken? ', 'what plane is this film ', 'in what plane is this image taken? ', 'what plane is the image acquired in? ', 'in what plane is this ct scan? ', 'which plane is the image shown in? ', 'what plane is the image acquired in? ', 'which plane is the image taken? ', 'what plane was used in this ct scan? ', 'what is the plane of the image? ', 'in what plane is this image taken? ', 'in which plane is the ct scan displayed? ', 'in what plane is this mri? ', 'in what plane is this ultrasound taken? ', 'in what plane was this image taken? ', 'what plane is this ct scan in? ', 'in what plane is this ct scan captured? ', 'what plane was used in this mri? ', 'which plane is this image in? ', 'what image plane is this? ', 'what is the plane of the x-ray? ', 'which plane is this image in? ', 'in what plane is this ct scan taken? ', 'which plane is the image shown in? ', 'in what plane is this mri taken? ', 'in what plane was this image taken? ', 'what plane was used in this ct scan? ', 'what plane was used in this x-ray? ', 'what is the plane of the x-ray? ', 'what plane is seen? ', 'in what plane is this x-ray taken? ', 'what is the plane? ', 'in which plane is the x-ray displayed? ', 'in what plane is this image taken? ', 'in what plane was this image taken? ', 'what plane is this? ', 'what plane was used in this mri? ', 'what plane was used in this ct scan? ', 'which plane is this mri taken in? ', 'what plane is this mri in? ', 'what plane is seen? ', 'in what plane is this ct scan? ', 'what is the plane? ', 'in what plane is this ct scan? ', 'what is the plane of this mri? ', 'which plane is this mri taken in? ', 'which plane is the image taken? ', 'which plane is this x-ray taken in? ', 'in what plane is this mammograph? ', 'what organ system is displayed in this ct scan? ', 'what is the organ principally shown in this mri? ', 'which organ is captured by this mri? ', 'what organ system is evaluated primarily? ', 'what organ system is evaluated primarily? ', 'what is one organ system seen in this image? ']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunava/miniconda3/envs/vqamedenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_sample {'image_feature': tensor([[[6.3676e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.4804e-02],\n",
      "         ...,\n",
      "         [1.4119e-03],\n",
      "         [5.5211e-03],\n",
      "         [3.6616e-04]],\n",
      "\n",
      "        [[1.6710e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.8773e-02],\n",
      "         ...,\n",
      "         [7.2278e-03],\n",
      "         [3.2115e-03],\n",
      "         [4.4287e-05]],\n",
      "\n",
      "        [[4.5462e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3459e-02],\n",
      "         ...,\n",
      "         [9.7449e-03],\n",
      "         [5.7160e-03],\n",
      "         [4.7371e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[6.0191e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.0231e-02],\n",
      "         ...,\n",
      "         [5.9691e-04],\n",
      "         [1.3343e-03],\n",
      "         [5.6330e-05]],\n",
      "\n",
      "        [[3.7994e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.6213e-02],\n",
      "         ...,\n",
      "         [2.7946e-03],\n",
      "         [1.4224e-03],\n",
      "         [7.5491e-04]],\n",
      "\n",
      "        [[4.6886e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3601e-02],\n",
      "         ...,\n",
      "         [6.6851e-04],\n",
      "         [0.0000e+00],\n",
      "         [1.1215e-04]]]), 'image_id': ['synpic40809', 'synpic46288', 'synpic58908', 'synpic37465', 'synpic57420', 'synpic28035', 'synpic18684', 'synpic40389', 'synpic26781', 'synpic32938', 'synpic40410', 'synpic35919', 'synpic48716', 'synpic34030', 'synpic33039', 'synpic19161', 'synpic40028', 'synpic43535', 'synpic53726', 'synpic51866', 'synpic20053', 'synpic4164', 'synpic20286', 'synpic16734', 'synpic36341', 'synpic55037', 'synpic33417', 'synpic22526', 'synpic21749', 'synpic59180', 'synpic34807', 'synpic50359', 'synpic26581', 'synpic56072', 'synpic49807', 'synpic27890', 'synpic37328', 'synpic50370', 'synpic32052', 'synpic42589', 'synpic56271', 'synpic46738', 'synpic50006', 'synpic50984', 'synpic26351', 'synpic19837', 'synpic56107', 'synpic19614', 'synpic56103', 'synpic9653', 'synpic49779', 'synpic39275', 'synpic30245', 'synpic45180', 'synpic26194', 'synpic53251', 'synpic16094', 'synpic36422', 'synpic35881', 'synpic25310', 'synpic28973', 'synpic50638', 'synpic49369', 'synpic36218'], 'question': ['what organ system is being imaged? ', 'what organ system is primarily present in this image? ', 'which organ system is imaged? ', 'what organ system is being imaged? ', 'which organ system is shown in the mri? ', 'what organ system is evaluated primarily? ', 'what organ system is evaluated primarily? ', 'what organ is this image of? ', 'what organ system is shown in the image? ', 'what organ system is primarily present in this image? ', 'what organ system is imaged? ', 'what organ system is imaged? ', 'what organ system is primarily present in this image? ', 'what part of the body does this x-ray show? ', 'what part of the body does this ct scan show? ', 'what part of the body is being imaged? ', 'what organ system is shown in this x-ray? ', 'what is the organ system in this image? ', 'which organ is captured by this ct scan? ', 'what organ system is imaged? ', 'what organ system is shown in the image? ', 'what organ system is pictured here? ', 'which organ system is imaged? ', 'what organ is this x-ray showing? ', 'what organ system is displayed in this mri? ', 'what organ systems can be evaluated with this mri? ', 'what organ system is evaluated primarily? ', 'what organ system is displayed in this x-ray? ', 'what organ system is visualized? ', 'what organ system is visualized? ', 'what organ system is visualized? ', 'what organ system is pictured here? ', 'what part of the body is being imaged? ', 'what organ system is evaluated primarily? ', 'what part of the body is being imaged here? ', 'the ultrasound shows what organ system? ', 'which organ system is imaged? ', 'which organ system is shown in the mri? ', 'what is the organ system in this image? ', 'what organ system is imaged? ', 'what organ system is imaged? ', 'which organ system is shown in the ct scan? ', 'which organ is captured by this ct scan? ', 'what organ system is pictured here? ', 'what organ is this mri showing? ', 'what organ system is primarily present in this image? ', 'what organ system is primarily present in this image? ', 'which organ system is shown in the ct scan? ', 'which organ system is shown in the ct scan? ', 'what organ system is shown in the image? ', 'what organ is this image of? ', 'what is the organ principally shown in this mri? ', 'what organ system is visualized? ', 'what organ system is shown in this mri? ', 'which organ system is shown in the ct scan? ', 'what part of the body is being imaged here? ', 'what organ system is being imaged? ', 'what organ is this image of? ', 'what is the organ system in this image? ', 'which organ is captured by this mri? ', 'what organ is this image showing? ', 'what organ system is primarily present in this image? ', 'what organ systems can be evaluated with this ct scan? ', 'what part of the body is being imaged? ']}\n",
      "batch_sample {'image_feature': tensor([[[0.0045],\n",
      "         [0.0000],\n",
      "         [0.0196],\n",
      "         ...,\n",
      "         [0.0002],\n",
      "         [0.0030],\n",
      "         [0.0016]],\n",
      "\n",
      "        [[0.0049],\n",
      "         [0.0000],\n",
      "         [0.0263],\n",
      "         ...,\n",
      "         [0.0023],\n",
      "         [0.0006],\n",
      "         [0.0003]],\n",
      "\n",
      "        [[0.0057],\n",
      "         [0.0000],\n",
      "         [0.0162],\n",
      "         ...,\n",
      "         [0.0122],\n",
      "         [0.0076],\n",
      "         [0.0023]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0073],\n",
      "         [0.0000],\n",
      "         [0.0122],\n",
      "         ...,\n",
      "         [0.0028],\n",
      "         [0.0019],\n",
      "         [0.0011]],\n",
      "\n",
      "        [[0.0049],\n",
      "         [0.0000],\n",
      "         [0.0152],\n",
      "         ...,\n",
      "         [0.0099],\n",
      "         [0.0002],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0051],\n",
      "         [0.0000],\n",
      "         [0.0239],\n",
      "         ...,\n",
      "         [0.0007],\n",
      "         [0.0005],\n",
      "         [0.0000]]]), 'image_id': ['synpic47608', 'synpic46516', 'synpic55230', 'synpic39301', 'synpic12184', 'synpic35275', 'synpic39472', 'synpic19991', 'synpic38220', 'synpic41907', 'synpic38591', 'synpic25311', 'synpic47557', 'synpic50003', 'synpic18251', 'synpic16242', 'synpic47964', 'synpic25139', 'synpic56302', 'synpic52164', 'synpic45430', 'synpic38424', 'synpic18938', 'synpic54475', 'synpic46071', 'synpic16108', 'synpic26975', 'synpic41736', 'synpic52038', 'synpic41044', 'synpic26752', 'synpic21029', 'synpic28025', 'synpic27699', 'synpic44464', 'synpic58717', 'synpic47804', 'synpic16487', 'synpic19950', 'synpic33613', 'synpic47187', 'synpic58925', 'synpic58716', 'synpic42982', 'synpic50835', 'synpic31561', 'synpic37104', 'synpic22284', 'synpic21941', 'synpic35129', 'synpic26814', 'synpic100313', 'synpic454', 'synpic50558', 'synpic55352', 'synpic47476', 'synpic58354', 'synpic39386', 'synpic25627', 'synpic49505', 'synpic28985', 'synpic29794', 'synpic45122', 'synpic100563'], 'question': ['what organ system is being imaged? ', 'what organ systems can be evaluated with this mri? ', 'what organ system is evaluated primarily? ', 'what organ is this mri showing? ', 'what part of the body is being imaged here? ', 'what organ system is evaluated primarily? ', 'what organ system is pictured here? ', 'what organ system is primarily present in this image? ', 'what organ system is primarily present in this image? ', 'what organ is this image of? ', 'what part of the body is being imaged here? ', 'what organ system is pictured here? ', 'what organ system is pictured here? ', 'what organ system is primarily present in this image? ', 'what organ system is primarily present in this image? ', 'what organ system is imaged? ', 'which organ is captured by this mri? ', 'what organ system is pictured here? ', 'what organ system is shown in the image? ', 'the ct scan shows what organ system? ', 'what organ system is primarily present in this image? ', 'what organ system is primarily present in this image? ', 'what organ system is evaluated primarily? ', 'what organ system is visualized? ', 'what part of the body does this mri show? ', 'what organ system is pictured here? ', 'which organ is captured by this ultrasound? ', 'what organ systems can be evaluated with this x-ray? ', 'what part of the body is being imaged? ', 'which organ system is shown in the mri? ', 'what organ system is pictured here? ', 'what organ system is shown in the image? ', 'what part of the body is being imaged? ', 'what organ system is shown in the image? ', 'what organ system is visualized? ', 'what part of the body is being imaged here? ', 'what organ system is displayed in this ct scan? ', 'what organ system is being imaged? ', 'what organ system is being imaged? ', 'what organ system is visualized? ', 'what organ is this image of? ', 'which organ system is imaged? ', 'what organ system is imaged? ', 'what organ system is evaluated primarily? ', 'what organ system is displayed in this ct scan? ', 'what part of the body is being imaged? ', 'the mri shows what organ system? ', 'what organ is this image of? ', 'what organ system is shown in the image? ', 'what organ system is being imaged? ', 'what is the organ principally shown in this mri? ', 'what organ is this x-ray showing? ', 'which organ system is imaged? ', 'what part of the body is being imaged? ', 'what part of the body is being imaged? ', 'is there something wrong in the image? ', 'is this a normal ultrasound? ', 'does this image look normal? ', 'does this image look normal? ', 'is this image normal? ', 'is the ultrasound normal? ', 'is this a normal ct scan? ', 'is the ct scan normal? ', 'is this image normal? ']}\n",
      "batch_sample {'image_feature': tensor([[[4.1872e-03],\n",
      "         [0.0000e+00],\n",
      "         [3.2426e-02],\n",
      "         ...,\n",
      "         [9.8209e-04],\n",
      "         [2.9652e-03],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[2.4551e-03],\n",
      "         [0.0000e+00],\n",
      "         [3.1185e-02],\n",
      "         ...,\n",
      "         [3.3391e-04],\n",
      "         [4.3707e-03],\n",
      "         [5.3993e-04]],\n",
      "\n",
      "        [[4.6365e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.2919e-02],\n",
      "         ...,\n",
      "         [4.1093e-03],\n",
      "         [1.7937e-03],\n",
      "         [7.3412e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.4358e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.0619e-02],\n",
      "         ...,\n",
      "         [1.5430e-05],\n",
      "         [2.1917e-03],\n",
      "         [5.1584e-04]],\n",
      "\n",
      "        [[7.0064e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.5771e-02],\n",
      "         ...,\n",
      "         [0.0000e+00],\n",
      "         [2.7871e-05],\n",
      "         [2.4536e-03]],\n",
      "\n",
      "        [[2.4743e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.4466e-02],\n",
      "         ...,\n",
      "         [5.9361e-04],\n",
      "         [1.7062e-03],\n",
      "         [1.7937e-04]]]), 'image_id': ['synpic25614', 'synpic53988', 'synpic23260', 'synpic18584', 'synpic36889', 'synpic55889', 'synpic47679', 'synpic48238', 'synpic23472', 'synpic20621', 'synpic33890', 'synpic21502', 'synpic23315', 'synpic59863', 'synpic52063', 'synpic43973', 'synpic33264', 'synpic35832', 'synpic36678', 'synpic36693', 'synpic59524', 'synpic23288', 'synpic58148', 'synpic54202', 'synpic54570', 'synpic25389', 'synpic28646', 'synpic35171', 'synpic45521', 'synpic42299', 'synpic56944', 'synpic38736', 'synpic31074', 'synpic31921', 'synpic59690', 'synpic50844', 'synpic31510', 'synpic58565', 'synpic48819', 'synpic43958', 'synpic19471', 'synpic51409', 'synpic46175', 'synpic41140', 'synpic19459', 'synpic59243', 'synpic23931', 'synpic52110', 'synpic24938', 'synpic44969', 'synpic41839', 'synpic100560', 'synpic40312', 'synpic39606', 'synpic35996', 'synpic54398', 'synpic57322', 'synpic22025', 'synpic24332', 'synpic31918', 'synpic33464', 'synpic24681', 'synpic19500', 'synpic28642'], 'question': ['is there something wrong in the image? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the ct scan? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the ct scan? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this ultrasound? ', 'what is most alarming about this gastrointestinal image? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this x-ray? ', 'what abnormality is seen in the image? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this ct scan? ', 'what is abnormal in the mri? ', 'what is most alarming about this ultrasound? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this mri? ', 'what abnormality is seen in the image? ', 'what abnormality is seen in the image? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the mri? ', 'what is the primary abnormality in this image? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this ct scan? ', 'what is abnormal in the ct scan? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the mri? ', 'what is most alarming about this x-ray? ', 'what is most alarming about this ultrasound? ', 'what abnormality is seen in the image? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this ct scan? ', 'what abnormality is seen in the image? ', 'what is the primary abnormality in this image? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the x-ray? ', 'what is abnormal in the mri? ', 'what is most alarming about this gastrointestinal image? ', 'what abnormality is seen in the image? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the ct scan? ', 'what abnormality is seen in the image? ', 'what is most alarming about this mri? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this mri? ', 'what is abnormal in the mri? ', 'what is abnormal in the ct scan? ', 'what is the primary abnormality in this image? ', 'what abnormality is seen in the image? ', 'what is abnormal in the gastrointestinal image? ', 'what abnormality is seen in the image? ', 'what abnormality is seen in the image? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this ct scan? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the ct scan? ', 'what abnormality is seen in the image? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this ct scan? ', 'what is abnormal in the ultrasound? ', 'what is abnormal in the gastrointestinal image? ']}\n",
      "batch_sample {'image_feature': tensor([[[6.1490e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.2918e-02],\n",
      "         ...,\n",
      "         [2.4349e-03],\n",
      "         [4.6949e-04],\n",
      "         [2.0112e-04]],\n",
      "\n",
      "        [[4.6230e-03],\n",
      "         [0.0000e+00],\n",
      "         [2.3228e-02],\n",
      "         ...,\n",
      "         [6.0133e-03],\n",
      "         [1.1464e-03],\n",
      "         [1.5751e-05]],\n",
      "\n",
      "        [[6.6405e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.6624e-02],\n",
      "         ...,\n",
      "         [1.8708e-03],\n",
      "         [9.5937e-04],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.8948e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3951e-02],\n",
      "         ...,\n",
      "         [4.7205e-03],\n",
      "         [0.0000e+00],\n",
      "         [8.4838e-05]],\n",
      "\n",
      "        [[3.9395e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.4576e-02],\n",
      "         ...,\n",
      "         [3.5113e-03],\n",
      "         [3.0022e-03],\n",
      "         [1.4435e-04]],\n",
      "\n",
      "        [[5.0979e-03],\n",
      "         [0.0000e+00],\n",
      "         [1.3818e-02],\n",
      "         ...,\n",
      "         [2.1043e-03],\n",
      "         [3.2623e-04],\n",
      "         [2.0160e-04]]]), 'image_id': ['synpic60174', 'synpic28495', 'synpic51803', 'synpic28324', 'synpic50710', 'synpic60189', 'synpic59091', 'synpic39017', 'synpic37984', 'synpic53580', 'synpic50923', 'synpic32787', 'synpic35942', 'synpic16143', 'synpic36293', 'synpic55708', 'synpic23846', 'synpic58210', 'synpic34453', 'synpic24668', 'synpic25012', 'synpic51792', 'synpic25761', 'synpic51976', 'synpic53807', 'synpic18351', 'synpic43433', 'synpic28709', 'synpic58577', 'synpic47443', 'synpic50705', 'synpic49254', 'synpic43590', 'synpic53967', 'synpic45637', 'synpic33979', 'synpic47008', 'synpic58869', 'synpic38637', 'synpic39501', 'synpic47961', 'synpic47550', 'synpic55154', 'synpic28154', 'synpic58276', 'synpic39844', 'synpic24183', 'synpic21789', 'synpic39878', 'synpic41525', 'synpic18173', 'synpic54143'], 'question': ['what is most alarming about this ct scan? ', 'what is abnormal in the gastrointestinal image? ', 'what is abnormal in the ct scan? ', 'what is the primary abnormality in this image? ', 'what abnormality is seen in the image? ', 'what is most alarming about this ct scan? ', 'what abnormality is seen in the image? ', 'what is most alarming about this mri? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this mri? ', 'what is abnormal in the mri? ', 'what is abnormal in the ultrasound? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this nuclear medicine image? ', 'what abnormality is seen in the image? ', 'what is abnormal in the mri? ', 'what is most alarming about this ct scan? ', 'what is most alarming about this mri? ', 'what is most alarming about this ct scan? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this mri? ', 'what abnormality is seen in the image? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the mri? ', 'what is most alarming about this ct scan? ', 'what abnormality is seen in the image? ', 'what is most alarming about this angiogram? ', 'what abnormality is seen in the image? ', 'what abnormality is seen in the image? ', 'what is most alarming about this mri? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the x-ray? ', 'what is abnormal in the mri? ', 'what abnormality is seen in the image? ', 'what is abnormal in the ct scan? ', 'what is abnormal in the mri? ', 'what is the primary abnormality in this image? ', 'is there an abnormality in the mri? ', 'what is the primary abnormality in this image? ', 'what abnormality is seen in the image? ', 'what is the primary abnormality in this image? ', 'what is most alarming about this mri? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the mri? ', 'what is abnormal in the mri? ', 'what is the primary abnormality in this image? ', 'what is abnormal in the ct scan? ', 'what is most alarming about this mri? ', 'what is most alarming about this ct scan? ', 'what is the primary abnormality in this image? ', 'what is the primary abnormality in this image? ']}\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,batch_sample in enumerate(test_data_loader):\n",
    "    # print('batch_sample',batch_sample)\n",
    "    image = batch_sample['image_feature'].to(device)\n",
    "    image_id = batch_sample['image_id']\n",
    "    questions = batch_sample['question']\n",
    "\n",
    "    output,img_emb,txt_emb = model(image,questions)\n",
    "    preds = torch.argmax(output,dim=-1)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "\n",
    "    assert(len(preds) == len(image_id))\n",
    "    ans_keys = list(answer_classes.keys())\n",
    "    ans_values = list(answer_classes.values())\n",
    "    \n",
    "    for pred, image_name in zip(preds, image_id):\n",
    "        index_ans = ans_values.index(pred)\n",
    "        results.append({image_name+'|'+ans_keys[index_ans]})\n",
    "        res['Image_id'].append(image_name)\n",
    "        res['Answer'].append(ans_keys[index_ans])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "test_df_res = pd.DataFrame(res)\n",
    "df.to_csv(path_change+'/submission_visualbert.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete in 1m 9s\n"
     ]
    }
   ],
   "source": [
    "time_elapsed = time.time() - since\n",
    "print('Evaluation complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = path_change + '/VQA_Med_2019_Dataset/Test/VQAMed2019Test'\n",
    "test_ref_path = test_path + '/VQAMed2019_Test_Questions_w_Ref_Answers.txt'\n",
    "\n",
    "with open(test_ref_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "dict_data = {'Image_id':[],\n",
    "            'Category':[],\n",
    "            'Question':[],\n",
    "            'Answer':[]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in lines:\n",
    "    # print('element',element)\n",
    "    pd_element = element.split('|')\n",
    "    # print('pd_element',pd_element[0])\n",
    "    dict_data['Image_id'].append(pd_element[0])\n",
    "    dict_data['Category'].append(pd_element[1])\n",
    "    dict_data['Question'].append(pd_element[2])\n",
    "    dict_data['Answer'].append(pd_element[3].strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(dict_data,columns=['Image_id','Category','Question','Answer'])\n",
    "\n",
    "pred = test_df_res['Answer'].to_list()\n",
    "\n",
    "truelabels = test_df['Answer'].to_list()\n",
    "\n",
    "test_df_res['truelabels'] = truelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.2\n"
     ]
    }
   ],
   "source": [
    "test_df_res.to_csv(path+'/visualbert_result.csv',index=False)\n",
    "\n",
    "cnt=0\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i] == truelabels[i]): cnt=cnt+1\n",
    "\n",
    "\n",
    "print((cnt/len(pred))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = res['Image_id']\n",
    "preds = res['Answer']\n",
    "questions = dict_data['Question']\n",
    "answers = dict_data['Answer']\n",
    "Image_ids = dict_data['Image_id']\n",
    "categories = dict_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_ids)):\n",
    "    if image_ids[i] != Image_ids[i]:\n",
    "        print('mismatch at index',i)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "correct ={'modality': 0, 'plane': 0, 'organ': 0, 'abnormality': 0}\n",
    "count ={'modality': 0, 'plane': 0, 'organ': 0, 'abnormality': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_ids)):\n",
    "    if (preds[i] == answers[i]): \n",
    "        cnt = cnt+1\n",
    "        correct[categories[i]] = correct[categories[i]]+1\n",
    "    count[categories[i]] = count[categories[i]]+1  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt 266\n",
      "correct {'modality': 91, 'plane': 84, 'organ': 80, 'abnormality': 11}\n",
      "count {'modality': 125, 'plane': 125, 'organ': 125, 'abnormality': 125}\n"
     ]
    }
   ],
   "source": [
    "print('cnt',cnt)\n",
    "print('correct',correct)\n",
    "print('count',count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqamedenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
